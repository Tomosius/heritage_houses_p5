{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7875c24c43c0d1e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Notebook 04 - Feature Engineering\n",
    "\n",
    "## Objectives\n",
    "\n",
    "Engineer Features for:\n",
    "* Classification\n",
    "* Regression\n",
    "* Clustering\n",
    "\n",
    "## Inputs\n",
    "* outputs/datasets/cleaned/test.csv\n",
    "\n",
    "## Outputs\n",
    "* Create Clean dataset:\n",
    "    * all new datasets of cleaning will be stored in inputs/datasets/cleaning\n",
    "* Split created dataset in to 3 parts:\n",
    "    * Train\n",
    "    * Validate\n",
    "    * Test\n",
    "* all new datasets (train, validate and test) will be stored in outputs/datasets/cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a32a78833a8ea4",
   "metadata": {},
   "source": [
    "## Change working directory\n",
    "In This section we will get location of current directory and move one step up, to parent folder, so App will be accessing project folder.\n",
    "\n",
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "id": "e9401ea48b42b5ff",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "126a0bc0c8389f95",
   "metadata": {},
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print('Current working directory is', os.getcwd())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "891d66d7edd5b491",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "d983f77e553443e0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('outputs/datasets/cleaned/train.parquet.gzip')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "46a82af219cc1b93",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Hypothesis 2 also Failed. There is possibility, where features interact between themselves making new ones, same time we can extract useful information from existing features.\n",
    "1. Encoding Changing (create dictionary for ordinal Encoder):\n",
    "    * When we encode Basement Exposure and Finish type, None becomes 0, and it is fine as There is no basement.\n",
    "    * When we encode Garage Finish, same issue, None becomes 0, there is no Garage\n",
    "    * Kitchen Quality - Po (Poor) becomes 0, what is wrong. What if it has to be positive or negative number, it interacts with others like:\n",
    "2. Create new mathematical sub_features:\n",
    "    * Basement:\n",
    "        * Basement Exposure mathematical manipulations with all Basement Areas\n",
    "        * Basement Finish Type manipulations with all Basement Areas\n",
    "    * Garage:\n",
    "        * Garage Finish mathematical manipulations with Garage Area\n",
    "    * Building:\n",
    "        * Overall Cond mathematical manipulations with building areas\n",
    "        * Overall Quality mathematical manipulations with building areas\n",
    "3. Extract information and create new sub_features (we know buildings dates are up to 2010):\n",
    "    * Garage Age = 2010 - Garage Year Built\n",
    "    * Building Age = 2010 - Year Built\n",
    "    * Remod Age = 2010 - Remodel Year\n",
    "    * Remod Age Test = If House was built and remodeled same year, this vale will be 0, else Remod Age\n",
    "4. Checking if house feature exist (maybe garage, porch or deck size does not matter, it mater that it is there):\n",
    "    * Has 2nd floor - If area of 2nd floor > 0, we will set to True, else False\n",
    "    * Has Basement - If building has basement = True, else False\n",
    "    * Has Garage - If building has Garage = True, else False\n",
    "    * Has Masonry Veneer - If building has masonry veneer = True, else False\n",
    "    * Has Enclosed Porch - If building has Enclosed Porch = True, else False\n",
    "    * Has Open Porch - If building has Open Porch = True, else False\n",
    "    * Has Any Porch - If building has any type of porch = True, else False\n",
    "    * Has Wooden Deck - If building Has wooden deck = True, else False\n",
    "\n",
    "After new features created, check any correlation with existing features and new ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467a753c543328df",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9855b432fc7eea37",
   "metadata": {},
   "source": [
    "### Categorical Features Encoding\n",
    "\n",
    "1. We will set encoder for values, so when we encode categorical features, they receive correct, or at least logical numbers\n",
    "2. We will add one more encoder with OneHotEncoder, so we can compare how they increase or decrease performance of model"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb2ebdf62465be8f",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Encoding Order as specified\n",
    "\n",
    "# Getting all categorical features as a list\n",
    "categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "\"\"\" For Kitchen Quality we will add 'NONE', otherwise encoding Po will be assigned 0\"\"\"\n",
    "order = {\n",
    "    'BsmtExposure': ['None', 'No', 'Mn', 'Av', 'Gd'],\n",
    "    'BsmtFinType1': ['None', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n",
    "    'GarageFinish': ['None', 'Unf', 'RFn', 'Fin'],\n",
    "    'KitchenQual': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "}\n",
    "\n",
    "# Initialize the OrdinalEncoder with the specified order\n",
    "encoder = OrdinalEncoder(categories=[order['BsmtExposure'],\n",
    "                                     order['BsmtFinType1'],\n",
    "                                     order['GarageFinish'],\n",
    "                                     order['KitchenQual']])\n",
    "\n",
    "# Fit and Transform the data\n",
    "df[categorical_features] = encoder.fit_transform(df[categorical_features])\n",
    "df[categorical_features] = pd.DataFrame(df, columns=categorical_features)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d6ded5521a0dba2f",
   "metadata": {},
   "source": [
    "### Basement Features\n",
    "\n",
    "First we will create new sub features using RelativeFeatures"
   ]
  },
  {
   "cell_type": "code",
   "id": "986e1d0a76fe8ce7",
   "metadata": {},
   "source": [
    "from feature_engine.creation import RelativeFeatures\n",
    "\n",
    "basement_features = ['BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF']\n",
    "transformer = RelativeFeatures(\n",
    "    variables=['BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF'],\n",
    "    reference=['BsmtExposure', 'BsmtFinType1'],\n",
    "    func=[\"sub\", \"mul\", \"add\"],  # We will try to subtract, multiply and add - sum features\n",
    ")\n",
    "df_basement = transformer.fit_transform(df[basement_features])\n",
    "df_basement.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "88f945cfa9033147",
   "metadata": {},
   "source": [
    "Now Using SmartCorrelatedSelection we will identify sets of them, so we do not need to work with all sub_features"
   ]
  },
  {
   "cell_type": "code",
   "id": "cc96cf54b459a519",
   "metadata": {},
   "source": [
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "tr = SmartCorrelatedSelection(\n",
    "    variables=None,\n",
    "    method=\"pearson\",\n",
    "    threshold=0.8,\n",
    "    missing_values=\"raise\",\n",
    "    selection_method=\"variance\",\n",
    "    estimator=None,\n",
    ")\n",
    "\n",
    "tr.fit_transform(df_basement)\n",
    "\n",
    "basement_feature_sets = tr.correlated_feature_sets_\n",
    "basement_feature_sets"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f050c66d18b77c0",
   "metadata": {},
   "source": [
    "Very nice, we can see sets, based on that we will select just what we need"
   ]
  },
  {
   "cell_type": "code",
   "id": "6d9c88d9a1a758e0",
   "metadata": {},
   "source": [
    "selected_features = []\n",
    "\n",
    "for feature_set in tr.correlated_feature_sets_:\n",
    "    # Calculate variances within each set\n",
    "    variances = {feature: df_basement[feature].var() for feature in feature_set}\n",
    "    # Select the feature with the highest variance\n",
    "    best_feature = max(variances, key=variances.get)\n",
    "    selected_features.append(best_feature)\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8c5f4b9eb2dddfad",
   "metadata": {},
   "source": [
    "We can see, that best features and their combinations are:\n",
    "1. TotalBsmtSF * BsmtExposure => Yes it looks good and logical\n",
    "2. TotalBsmtSF * BsmtFinType1 => Also logical\n",
    "3. BsmtFinSF1 * BsmtFinType1 => Very Logical\n",
    "4. BsmtUnfSF - BsmtFinType1 => Doubt it, it is unfinished area minus finish type \n",
    "5. TotalBsmtSF + BsmtFinType1 => also not very Logical\n",
    "\n",
    "We will make new sub Features like this (will add to all new sub_features xxx at start, this will help to identify them):\n",
    "```python\n",
    "df['xxx_TotalBsmtSF_mul_BsmtExposure'] = df['TotalBsmtSF'] * df['BsmtExposure']\n",
    "df['xxx_TotalBsmtSF_mul_BsmtFinType1'] = df['TotalBsmtSF'] * df['BsmtFinSF1']\n",
    "df['xxx_BsmtFinSF1_mul_BsmtFinType1'] = df['BsmtFinType1'] * df['BsmtFinSF1']\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['xxx_TotalBsmtSF_mul_BsmtExposure'] = df['TotalBsmtSF'] * df['BsmtExposure']\n",
    "df['xxx_TotalBsmtSF_mul_BsmtFinType1'] = df['TotalBsmtSF'] * df['BsmtFinSF1']\n",
    "df['xxx_BsmtFinSF1_mul_BsmtFinType1'] = df['BsmtFinType1'] * df['BsmtFinSF1']"
   ],
   "id": "b79c9f1a0aa90227",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Garage Features",
   "id": "dcbcd22a67778b14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['xxx_GarageFinish_mul_GarageArea'] = df['GarageFinish'] * df['GarageArea']",
   "id": "3b72d352d8a28c44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Will add code to creating new sub_features:\n",
    "```python\n",
    "df['xxx_GarageFinish_mul_GarageArea'] = df['GarageFinish'] * df['GarageArea']\n",
    "```"
   ],
   "id": "16b5188546db513"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Building sub_features:\n",
    "\n",
    "Now this is extremely hard part. As it is we have 2 categories for building:\n",
    "* Overal Quality - Rates overall material Finish of the house\n",
    "* Overal Condition - Rates Overall condition of the house\n",
    "Logically thinking it should apply to whole building, so we could manipulate these vales (After ordinal encoding with dictionary) to Sale Price. But we can not, as it does not apply to:\n",
    "* Lot Area\n",
    "* Lot Frontage\n",
    "* Porches, etc\n",
    "\n",
    "Based on all dataset observation, it *should* apply just to living Areas. We can do it in 2 ways:\n",
    "* Sum all living areas of building and make mathematical manipulations with those 2 categories\n",
    "* Apply Mathematical Manipulations of each category to each are of building: ground level, 1st and 2nd floors individually\n",
    "\n",
    "We will do both manipulations, and using smart correlation will select just best ones. Do not want to add to many new sub_features, as it can become noisy in ML."
   ],
   "id": "2523ad53d49fd044"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from feature_engine.creation import RelativeFeatures\n",
    "df['xxx_TotalLivingArea'] = df['GrLivArea'] + df['1stFlrSF'] + df['2ndFlrSF']\n"
   ],
   "id": "76ad851e66e4bc5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from feature_engine.creation import RelativeFeatures\n",
    "\n",
    "\n",
    "living_features = ['GrLivArea', '1stFlrSF', '2ndFlrSF', 'xxx_TotalLivingArea', 'OverallCond', 'OverallQual']\n",
    "transformer = RelativeFeatures(\n",
    "    variables=['GrLivArea', '1stFlrSF', '2ndFlrSF', 'xxx_TotalLivingArea'],\n",
    "    reference=['OverallCond', 'OverallQual'],\n",
    "    func=[\"mul\"]\n",
    ")\n",
    "df_living_area = transformer.fit_transform(df[living_features])\n",
    "df_living_area.head()"
   ],
   "id": "f46ad552a1218bcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lets check correlation between all of them and select best ones",
   "id": "1fc54b4ed4bae9e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "tr = SmartCorrelatedSelection(\n",
    "    variables=None,\n",
    "    method=\"pearson\",\n",
    "    threshold=0.9,\n",
    "    missing_values=\"raise\",\n",
    "    selection_method=\"variance\",\n",
    "    estimator=None,\n",
    ")\n",
    "\n",
    "tr.fit_transform(df_living_area)\n",
    "\n",
    "living_area_sets = tr.correlated_feature_sets_\n",
    "living_area_sets"
   ],
   "id": "25ac78796d08f69c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "selected_features = []\n",
    "\n",
    "for feature_set in tr.correlated_feature_sets_:\n",
    "    # Calculate variances within each set\n",
    "    variances = {feature: df_living_area[feature].var() for feature in feature_set}\n",
    "    # Select the feature with the highest variance\n",
    "    best_feature = max(variances, key=variances.get)\n",
    "    selected_features.append(best_feature)\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n"
   ],
   "id": "e49d54ab7ddf45fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can see we are getting these sets:\n",
    "* 'xxx_Total_living_area_mul_OverallQual' - Logical and agreed, we will keep this sub_feature\n",
    "* '1stFlrSF_mul_OverallQual' - also logical, we will keep it\n",
    "* '2ndFlrSF_mul_OverallQual' - Also logical\n",
    "* 'xxx_Total_living_area_mul_OverallCond' - also logical.\n",
    "\n",
    "We will keep all these new sub_features and will add code for creating new subfeatures:\n",
    "```python\n",
    "df['xxx_TotalLivingArea'] = df['GrLivArea'] + df['1stFlrSF'] + df['2ndFlrSF']\n",
    "df['xxx_TotalLivingArea_mul_OverallQual'] = df['xxx_TotalLivingArea'] * df['OverallQual']\n",
    "df['xxx_TotalLivingArea_mul_OverallCond'] = df['xxx_TotalLivingArea'] * df['OverallCond']\n",
    "df['xxx_1stFlrSF_mul_OverallQual'] = df['1stFlrSF'] * df['OverallQual']\n",
    "df['xxx_2ndFlrSF_mul_OverallQual'] = df['2ndFlrSF'] * df['OverallQual']\n",
    "```"
   ],
   "id": "ff0ac2f9576ed409"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extraction of information form Features and creating new ones",
   "id": "deb5a7dff152cf85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['xxx_Age_Garage'] = 2010 - df['GarageYrBlt']\n",
    "df['xxx_Age_Build'] = 2010 - df['YearBuilt']\n",
    "df['xxx_Age_Remod'] = 2010 - df['YearRemodAdd']\n",
    "df['xxx_Remod_TEST'] = df.apply(lambda row: 0 if row['xxx_Age_Build'] == row['xxx_Age_Remod'] else row['xxx_Age_Remod'], axis=1)"
   ],
   "id": "c33395f385b784c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Adding code to new subfeatures creation:\n",
    "```python\n",
    "df['xxx_Age_Garage'] = 2010 - df['GarageYrBlt']\n",
    "df['xxx_Age_Build'] = 2010 - df['YearBuilt']\n",
    "df['xxx_Age_Remod'] = 2010 - df['YearRemodAdd']\n",
    "df['xxx_Remod_TEST'] = df.apply(lambda row: 0 if row['xxx_Age_Build'] == row['xxx_Age_Remod'] else row['xxx_Age_Remod'], axis=1)\n",
    "```"
   ],
   "id": "b076d0971d1165ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Checking Features if they exist and creating new ones\n",
    "\n",
    "After Feature is crrrated, we will save them as INT - easier for Machine Learning"
   ],
   "id": "c1e671b84c43c096"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[('xxx_Has_2nd_floor')] = df.apply(lambda row: False if row['2ndFlrSF'] == 0  else True, axis=1).astype(int)\n",
    "df[('xxx_Has_basement')] = df.apply(lambda row: False if row['TotalBsmtSF'] == 0  else True, axis=1).astype(int)\n",
    "df[('xxx_Has_garage')] = df.apply(lambda row: False if row['GarageArea'] ==0  else True, axis=1).astype(int)\n",
    "df[('xxx_Has_Masonry_Veneer')] = df.apply(lambda row: False if row['MasVnrArea'] ==0  else True, axis=1).astype(int)\n",
    "df[('xxx_Has_Enclosed_Porch')] = df.apply(lambda row: False if row['EnclosedPorch'] ==0  else True, axis=1).astype(int)\n",
    "df[('xxx_Has_Open_Porch')] = df.apply(lambda row: False if row['OpenPorchSF'] ==0  else True, axis=1).astype(int)\n",
    "df['xxx_Has_ANY_Porch'] = df['xxx_Has_Enclosed_Porch'] | df['xxx_Has_Open_Porch'].astype(int)\n",
    "df[('xxx_Has_Wooden_Deck')] = df.apply(lambda row: False if row['WoodDeckSF'] ==0  else True, axis=1).astype(int)"
   ],
   "id": "52313aab0af1d098",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Code to create new sub_features",
   "id": "a2033d5b2a911608"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['xxx_TotalBsmtSF_mul_BsmtExposure'] = df['TotalBsmtSF'] * df['BsmtExposure']\n",
    "df['xxx_TotalBsmtSF_mul_BsmtFinType1'] = df['TotalBsmtSF'] * df['BsmtFinSF1']\n",
    "df['xxx_BsmtFinSF1_mul_BsmtFinType1'] = df['BsmtFinType1'] * df['BsmtFinSF1']\n",
    "df['xxx_GarageFinish_mul_GarageArea'] = df['GarageFinish'] * df['GarageArea']\n",
    "df['xxx_TotalLivingArea'] = df['GrLivArea'] + df['1stFlrSF'] + df['2ndFlrSF']\n",
    "df['xxx_TotalLivingArea_mul_OverallQual'] = df['xxx_TotalLivingArea'] * df['OverallQual']\n",
    "df['xxx_TotalLivingArea_mul_OverallCond'] = df['xxx_TotalLivingArea'] * df['OverallCond']\n",
    "df['xxx_1stFlrSF_mul_OverallQual'] = df['1stFlrSF'] * df['OverallQual']\n",
    "df['xxx_2ndFlrSF_mul_OverallQual'] = df['2ndFlrSF'] * df['OverallQual']\n",
    "df['xxx_Age_Garage'] = 2010 - df['GarageYrBlt']\n",
    "df['xxx_Age_Build'] = 2010 - df['YearBuilt']\n",
    "df['xxx_Age_Remod'] = 2010 - df['YearRemodAdd']\n",
    "df['xxx_Remod_TEST'] = df.apply(lambda row: 0 if row['xxx_Age_Build'] == row['xxx_Age_Remod'] else row['xxx_Age_Remod'], axis=1)\n",
    "df[('xxx_Has_2nd_floor')] = df.apply(lambda row: False if row['2ndFlrSF'] == 0  else True, axis=1).astype(int)\n",
    "df[('xxx_Has_basement')] = df.apply(lambda row: False if row['TotalBsmtSF'] == 0  else True, axis=1).astype(int)\n",
    "df[('xxx_Has_garage')] = df.apply(lambda row: False if row['GarageArea'] ==0  else True, axis=1).astype(int)\n",
    "df[('xxx_Has_Masonry_Veneer')] = df.apply(lambda row: False if row['MasVnrArea'] ==0  else True, axis=1).astype(int)\n",
    "df[('xxx_Has_Enclosed_Porch')] = df.apply(lambda row: False if row['EnclosedPorch'] ==0  else True, axis=1).astype(int)\n",
    "df[('xxx_Has_Open_Porch')] = df.apply(lambda row: False if row['OpenPorchSF'] ==0  else True, axis=1).astype(int)\n",
    "df['xxx_Has_ANY_Porch'] = df['xxx_Has_Enclosed_Porch'] | df['xxx_Has_Open_Porch'].astype(int)\n",
    "df[('xxx_Has_Wooden_Deck')] = df.apply(lambda row: False if row['WoodDeckSF'] ==0  else True, axis=1).astype(int)"
   ],
   "id": "b4847d79104b514e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Checking for any transformations needed to all features and new sub_features.\n"
   ],
   "id": "43ee75ab5d3f8f23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from feature_engine import transformation as vt\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def FeatureEngineeringAnalysis(df, analysis_type=None, plot=False):\n",
    "    \"\"\"\n",
    "    - used for quick feature engineering on numerical and categorical variables\n",
    "    to decide which transformation can better transform the distribution shape \n",
    "    - Once transformed, use a reporting tool, like pandas-profiling, to evaluate distributions\n",
    "  \n",
    "    \"\"\"\n",
    "    check_missing_values(df)\n",
    "    allowed_types = ['numerical', 'ordinal_encoder', 'outlier_winsorizer']\n",
    "    check_user_entry_on_analysis_type(analysis_type, allowed_types)\n",
    "    list_column_transformers = define_list_column_transformers(analysis_type)\n",
    "\n",
    "    # Loop in each variable and engineer the data according to the analysis type\n",
    "    df_feat_eng = pd.DataFrame([])\n",
    "    for column in df.columns:\n",
    "        # create additional columns (column_method) to apply the methods\n",
    "        df_feat_eng = pd.concat([df_feat_eng, df[column]], axis=1)\n",
    "        for method in list_column_transformers:\n",
    "            df_feat_eng[f\"{column}_{method}\"] = df[column]\n",
    "\n",
    "        # Apply transformers in respectives column_transformers\n",
    "        df_feat_eng, list_applied_transformers = apply_transformers(analysis_type, df_feat_eng, column)\n",
    "\n",
    "        if plot == True:\n",
    "            # For each variable, assess how the transformations perform\n",
    "            transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return df_feat_eng\n",
    "\n",
    "\n",
    "def check_user_entry_on_analysis_type(analysis_type, allowed_types):\n",
    "    ### Check analysis type\n",
    "    if analysis_type == None:\n",
    "        raise SystemExit(f\"You should pass analysis_type parameter as one of the following options: {allowed_types}\")\n",
    "    if analysis_type not in allowed_types:\n",
    "        raise SystemExit(f\"analysis_type argument should be one of these options: {allowed_types}\")\n",
    "\n",
    "\n",
    "def check_missing_values(df):\n",
    "    if df.isna().sum().sum() != 0:\n",
    "        raise SystemExit(\n",
    "            f\"There is missing value in your dataset. Please handle that before getting into feature engineering.\")\n",
    "\n",
    "\n",
    "def define_list_column_transformers(analysis_type):\n",
    "    # Initialize an empty list for storing transformer names\n",
    "    list_column_transformers = []\n",
    "\n",
    "    # Numerical analysis transformers\n",
    "    if analysis_type == 'numerical':\n",
    "        list_column_transformers = [\"log_e\", \"log_10\", \"reciprocal\", \"power\", \"box_cox\", \"yeo_johnson\"]\n",
    "\n",
    "    # Transformer for ordinal encoding\n",
    "    elif analysis_type == 'ordinal_encoder':\n",
    "        list_column_transformers = [\"ordinal_encoder\"]\n",
    "\n",
    "    # Transformer for outlier handling via winsorization\n",
    "    elif analysis_type == 'outlier_winsorizer':\n",
    "        list_column_transformers = ['iqr']\n",
    "\n",
    "    return list_column_transformers\n",
    "\n",
    "\n",
    "def apply_transformers(analysis_type, df_feat_eng, column):\n",
    "    for col in df_feat_eng.select_dtypes(include='category').columns:\n",
    "        df_feat_eng[col] = df_feat_eng[col].astype('object')\n",
    "\n",
    "    if analysis_type == 'numerical':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_Numerical(df_feat_eng, column)\n",
    "\n",
    "    elif analysis_type == 'outlier_winsorizer':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_OutlierWinsorizer(df_feat_eng, column)\n",
    "\n",
    "    elif analysis_type == 'ordinal_encoder':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_CategoricalEncoder(df_feat_eng, column)\n",
    "\n",
    "    elif analysis_type == 'onehot_encoder':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_OneHotEncoder(df_feat_eng, column)\n",
    "\n",
    "    return df_feat_eng, list_applied_transformers\n",
    "\n",
    "\n",
    "def transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng):\n",
    "    # For each variable, assess how the transformations perform\n",
    "    print(f\"* Variable Analyzed: {column}\")\n",
    "    print(f\"* Applied transformation: {list_applied_transformers} \\n\")\n",
    "    for col in [column] + list_applied_transformers:\n",
    "\n",
    "        if analysis_type != 'ordinal_encoder':\n",
    "            DiagnosticPlots_Numerical(df_feat_eng, col)\n",
    "\n",
    "        else:\n",
    "            if col == column:\n",
    "                DiagnosticPlots_Categories(df_feat_eng, col)\n",
    "            else:\n",
    "                DiagnosticPlots_Numerical(df_feat_eng, col)\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "def DiagnosticPlots_Categories(df_feat_eng, col):\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.countplot(data=df_feat_eng, x=col, palette=['#432371'], order=df_feat_eng[col].value_counts().index)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.suptitle(f\"{col}\", fontsize=30, y=1.05)\n",
    "    plt.show()\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def DiagnosticPlots_Numerical(df, variable):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    sns.histplot(data=df, x=variable, kde=True, element=\"step\", ax=axes[0])\n",
    "    stats.probplot(df[variable], dist=\"norm\", plot=axes[1])\n",
    "    sns.boxplot(x=df[variable], ax=axes[2])\n",
    "\n",
    "    axes[0].set_title('Histogram')\n",
    "    axes[1].set_title('QQ Plot')\n",
    "    axes[2].set_title('Boxplot')\n",
    "    fig.suptitle(f\"{variable}\", fontsize=30, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def FeatEngineering_CategoricalEncoder(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "    try:\n",
    "        encoder = OrdinalEncoder(encoding_method='arbitrary', variables=[f\"{column}_ordinal_encoder\"])\n",
    "        df_feat_eng = encoder.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_ordinal_encoder\")\n",
    "\n",
    "    except:\n",
    "        df_feat_eng.drop([f\"{column}_ordinal_encoder\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "def FeatEngineering_OneHotEncoder(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "    try:\n",
    "        encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "        encoded_cols = encoder.fit_transform(df_feat_eng[[column]])\n",
    "        encoded_df = pd.DataFrame(encoded_cols, columns=encoder.get_feature_names_out([column]))\n",
    "        df_feat_eng = pd.concat([df_feat_eng, encoded_df], axis=1)\n",
    "        list_methods_worked.append(f\"{column}_onehot_encoder\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        df_feat_eng.drop([f\"{column}_onehot_encoder\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked\n",
    "\n",
    "\n",
    "def FeatEngineering_OutlierWinsorizer(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "\n",
    "    ### Winsorizer iqr\n",
    "    try:\n",
    "        disc = Winsorizer(\n",
    "            capping_method='iqr', tail='both', fold=1.5, variables=[f\"{column}_iqr\"])\n",
    "        df_feat_eng = disc.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_iqr\")\n",
    "    except:\n",
    "        df_feat_eng.drop([f\"{column}_iqr\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def FeatEngineering_Numerical(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "\n",
    "    # LogTransformer base e\n",
    "    try:\n",
    "        lt = vt.LogTransformer(variables=[f\"{column}_log_e\"])\n",
    "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_log_e\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_log_e\"], axis=1, inplace=True)\n",
    "\n",
    "    # LogTransformer base 10\n",
    "    try:\n",
    "        lt = vt.LogTransformer(variables=[f\"{column}_log_10\"], base='10')\n",
    "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_log_10\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_log_10\"], axis=1, inplace=True)\n",
    "\n",
    "    # ReciprocalTransformer\n",
    "    try:\n",
    "        rt = vt.ReciprocalTransformer(variables=[f\"{column}_reciprocal\"])\n",
    "        df_feat_eng = rt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_reciprocal\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_reciprocal\"], axis=1, inplace=True)\n",
    "\n",
    "    # PowerTransformer\n",
    "    try:\n",
    "        pt = vt.PowerTransformer(variables=[f\"{column}_power\"])\n",
    "        df_feat_eng = pt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_power\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_power\"], axis=1, inplace=True)\n",
    "\n",
    "    # BoxCoxTransformer\n",
    "    try:\n",
    "        bct = vt.BoxCoxTransformer(variables=[f\"{column}_box_cox\"])\n",
    "        df_feat_eng = bct.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_box_cox\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_box_cox\"], axis=1, inplace=True)\n",
    "\n",
    "    # YeoJohnsonTransformer\n",
    "    try:\n",
    "        yjt = vt.YeoJohnsonTransformer(variables=[f\"{column}_yeo_johnson\"])\n",
    "        df_feat_eng = yjt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_yeo_johnson\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_yeo_johnson\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked"
   ],
   "id": "b76200c3550cfda3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = FeatureEngineeringAnalysis(df, analysis_type='numerical', plot=False)",
   "id": "d76a6dbb27a86ea0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will use our Custom Function to plot all transformations",
   "id": "2dfa66844adcf8fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_dataframe(df, target):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from scipy.stats import spearmanr, kendalltau, probplot\n",
    "\n",
    "    # Configure plot settings\n",
    "    save_plot = True  # Set to False if you do not wish to save the plot\n",
    "    path = './plots'  # Directory to save the plots\n",
    "\n",
    "    for col in df.columns:\n",
    "        # Validate input types\n",
    "        if not isinstance(df[col], pd.Series) or not isinstance(target, pd.Series):\n",
    "            raise ValueError(\"Both feature and target must be pandas Series.\")\n",
    "\n",
    "        # Calculate correlation coefficients\n",
    "        pearson_corr = df[col].corr(target, method='pearson')\n",
    "        spearman_corr = spearmanr(df[col], target)[0]\n",
    "        kendall_corr = kendalltau(df[col], target)[0]\n",
    "\n",
    "        # Create the figure and axes\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(7, 10), gridspec_kw={\"height_ratios\": [1, 8, 8]})\n",
    "        fig.suptitle(f\"{col}\")\n",
    "\n",
    "        # Boxplot\n",
    "        sns.boxplot(data=df, x=df[col].name, ax=axes[0])\n",
    "        axes[0].set_title(f\"{df[col].name} Boxplot\")\n",
    "\n",
    "        # Histogram with KDE, setting KDE curve color to red\n",
    "        sns.histplot(data=df, x=df[col].name, kde=True, ax=axes[1], line_kws={'color': 'red', 'lw': 2})\n",
    "        axes[1].set_title(f\"{df[col].name} Distribution - Histogram\")\n",
    "\n",
    "        # Q-Q plot for normality\n",
    "        probplot(df[col], dist=\"norm\", plot=axes[2], fit=True)\n",
    "        axes[2].set_title(f\"{df[col].name} Q-Q Plot\")\n",
    "\n",
    "        # Setting the main title for the figure\n",
    "        fig.suptitle(f\"{df[col].name} Plot\")\n",
    "\n",
    "        # Calculating statistics\n",
    "        mean = df[col].mean()\n",
    "        median = df[col].median()\n",
    "        mode = df[col].mode()[0] if not df[col].mode().empty else 'NA'\n",
    "        IQR = df[col].quantile(0.75) - df[col].quantile(0.25)\n",
    "        skewness = df[col].skew()\n",
    "        kurtosis = df[col].kurt()\n",
    "        outlier_range_min = df[col].quantile(0.25) - 1.5 * IQR\n",
    "        outlier_range_max = df[col].quantile(0.75) + 1.5 * IQR\n",
    "\n",
    "        # Annotations with different colors and transparency\n",
    "        text_x = 0.95\n",
    "        text_y = 0.95\n",
    "\n",
    "        stats_texts = (\n",
    "            f\"Skewness: {'{:.2f}'.format(skewness) if isinstance(skewness, (int, float)) else 'N/A'}\\n \"\n",
    "            f\"Kurtosis: {'{:.2f}'.format(kurtosis) if isinstance(kurtosis, (int, float)) else 'N/A'}\\n\"\n",
    "            f\"Mean: {'{:.2f}'.format(mean) if isinstance(mean, (int, float)) else 'N/A'}\\n \"\n",
    "            f\"Median: {'{:.2f}'.format(median) if isinstance(median, (int, float)) else 'N/A'}\\n \"\n",
    "            f\"Mode: {'{:.2f}'.format(mode) if isinstance(mode, (int, float)) else 'N/A'}\\n\"\n",
    "            f\"IQR: {'{:.2f}'.format(IQR) if isinstance(IQR, (int, float)) else 'N/A'}\\n \"\n",
    "            f\"Non-outlier range: [{'{:.2f}'.format(outlier_range_min) if isinstance(outlier_range_min, (int, float)) else 'N/A'}, {'{:.2f}'.format(outlier_range_max) if isinstance(outlier_range_max, (int, float)) else 'N/A'}]\\n\"\n",
    "            f\"Pearson: {'{:.2f}'.format(pearson_corr) if isinstance(pearson_corr, (int, float)) else 'N/A'}\\n \"\n",
    "            f\"Spearman: {'{:.2f}'.format(spearman_corr) if isinstance(spearman_corr, (int, float)) else 'N/A'}\\n \"\n",
    "            f\"Kendall-Tau: {'{:.2f}'.format(kendall_corr) if isinstance(kendall_corr, (int, float)) else 'N/A'}\"\n",
    "        )\n",
    "\n",
    "        # Place the text box on the histogram plot\n",
    "        axes[1].text(text_x, text_y, stats_texts, transform=axes[1].transAxes, verticalalignment='top',\n",
    "                     horizontalalignment='right', fontsize=10, bbox=dict(boxstyle=\"round,pad=0.5\",\n",
    "                                                                         facecolor='white', edgecolor='gray',\n",
    "                                                                         alpha=0.9))\n",
    "\n",
    "        # Display the plot\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        # Save the plot with the feature name as the filename\n",
    "        if save_plot:\n",
    "            plt.savefig(os.path.join(path, f\"{df[col].name}.png\"))\n",
    "\n",
    "        #plt.show()\n",
    "        plt.close()"
   ],
   "id": "89771ccb37a12211",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_dataframe(df, df['SalePrice'])",
   "id": "8f951b2e6beecd97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature Transformations Exploration\n",
    "\n",
    "\n",
    "|FEATURES|1st Option     |   |2nd Option     |   |3rd Option    |   |\n",
    "|--------|---------------|---------|---------------|---------|--------------|---------|\n",
    "|        |Transformation |Outliers |Transformation |Outliers |Transformation|Outliers |\n",
    "|'1stFlrSF'|Yeo Johnson    |Low      |Box cox        |Low      |Log_e         |Low      |\n",
    "|'2ndFlrSF'|Yeo Johnson    |None     |Power          |None     |Original Vales|Low      |\n",
    "| 'BedroomAbvGr'|Yeo Johnson    |Low      |Box cox        |Low      |Power         |Low      |\n",
    "| 'BsmtExposure'|Yeo Johnson    |Low      |Power          |Low      |Original Vales|Low      |\n",
    "|'BsmtFinSF1'|Original Values|Low      |Power          |None     |Yeo Johnson   |None     |\n",
    "|'BsmtFinType1'|Original Values|None     |Yeo Johnson    |None     |Power         |None     |\n",
    "| 'BsmtUnfSF'|Yeo Johnson    |Low      |Power          |Low      |Original Vales|Medium   |\n",
    "| 'EnclosedPorch'|Yeo Johnson    |Low      |Power          |High     |Original Vales|Very High|\n",
    "| 'GarageArea'|Yeo Johnson    |Medium   |Original Values|High     |Power         |Medium   |\n",
    "| 'GarageFinish'|Yeo Johnson    |None     |Original Values|None     |Power         |Low      |\n",
    "| 'GarageYrBlt'|Power          |Low      |Reciprocal     |Low      |Log_e         |Low      |\n",
    "| 'GrLivArea'|Yeo Johnson    |Low      |Power          |Medium   |Log_e         |Low      |\n",
    "| 'KitchenQual'|Yeo Johnson    |None     |Power          |None     |Log_e         |None     |\n",
    "| 'LotArea'|Yeo Johnson    |Very High|Log_e          |Very High|Reciprocal    |Very High|\n",
    "| 'LotFrontage'|Power          |Very High|Yeo Johnson    |Very High|Log_e         |Very High|\n",
    "| 'MasVnrArea'|Yeo Johnson    |None     |Power          |Low      |Original Vales|X High   |\n",
    "| 'OpenPorchSF'|Yeo Johnson    |None     |Power          |Low      |Original Vales|X High   |\n",
    "| 'OverallCond'|Yeo Johnson    |Low      |Power          |Low      |Original Vales|Low      |\n",
    "| 'OverallQual'|Original Values|Low      |Yeo Johnson    |Low      |Power         |Low      |\n",
    "| 'TotalBsmtSF'|Yeo Johnson    |High     |Original Values|High     |Power         |Medium   |\n",
    "| 'WoodDeckSF'|Yeo Johnson    |Low      |Power          |X High   |Original Vales|X High   |\n",
    "| 'YearBuilt'|Original Values|Low      |Power          |Low      |Log_e         |Low      |\n",
    "| 'YearRemodAdd'|Power          |None     |Log_e          |None     |Original Vales|None     |\n",
    "| 'SalePrice'|Yeo Johnson    |High     |Log_e          |High     |Original Vales|X High   |\n",
    "| 'xxx_TotalBsmtSF_mul_BsmtExposure'|Yeo Johnson    |X High   |Power          |X High   |Original Vales|X High   |\n",
    "|'xxx_TotalBsmtSF_mul_BsmtFinType1'|Power          |Low      |Yeo Johnson    |None     |Original Vales|X High   |\n",
    "|'xxx_BsmtFinSF1_mul_BsmtFinType1'|Yeo Johnson    |None     |Power          |None     |Original Vales|Low      |\n",
    "| 'xxx_GarageFinish_mul_GarageArea'|Yeo Johnson    |Low      |Power          |Low      |Original Vales|High     |\n",
    "| 'xxx_Total_living_area'|Yeo Johnson    |Low      |Log_e          |Low      |Power         |Medium   |\n",
    "| 'xxx_Age_Garage'|Yeo Johnson    |None     |Power          |None     |Original Vales|Low      |\n",
    "| 'xxx_Age_Build'|Power          |None     |Yeo Johnson    |None     |Original Vales|Low      |\n",
    "| 'xxx_Age_Remod'|Yeo Johnson    |None     |Power          |None     |Original Vales|None     |\n",
    "| 'xxx_Remod_TEST'|Yeo Johnson    |None     |Power          |None     |Original Vales|Medium   |\n",
    "|'xxx_Has_2nd_floor'|Original Values|None     |               |         |              |         |\n",
    "| 'xxx_Has_basement'|Original Values|Low      |               |         |              |         |\n",
    "| 'xxx_Has_garage'|Original Values|Low      |               |         |              |         |\n",
    "| 'xxx_Has_Masonry_Veneer'|Original Values|None     |               |         |              |         |\n",
    "| 'xxx_Has_Enclosed_Porch'|Original Values|Low      |               |         |              |         |\n",
    "| 'xxx_Has_Open_Porch'|Original Values|None     |               |         |              |         |\n",
    "| 'xxx_Has_ANY_Porch'|Original Values|None     |               |         |              |         |\n",
    "| 'xxx_Has_wwooden_Deck'|Original Values|Low      |               |         |              |         |\n",
    "| 'xxx_TotalLivingArea'|Yeo Johnson    |Low      |Log_e          |Low      |Power         |Medium   |\n",
    "| 'xxx_TotalLivingArea_mul_OverallQual'|Yeo Johnson    |Low      |Power          |Medium   |Log_e         |Low      |\n",
    "| 'xxx_TotalLivingArea_mul_OverallCond'|Yeo Johnson    |High     |Log_e          |High     |Power         |X High   |\n",
    "|'xxx_1stFlrSF_mul_OverallQual'|Yeo Johnson    |Low      |Power          |High     |Log_e         |Medium   |\n",
    "|'xxx_2ndFlrSF_mul_OverallQual'|Yeo Johnson    |None     |Power          |None     |Original Vales|Medium   |\n"
   ],
   "id": "ede3e41e6646b017"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "All Features Original Values or Transformations, where outliers are High or X high, will be applied Winsorizer",
   "id": "41e648c0a6ac7297"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
