{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Predicting SalePrice\n",
    "\n",
    "## Objectives\n",
    "\n",
    "Create and evaluate model to predict SalePrice of building\n",
    "\n",
    "## Inputs:\n",
    "* outputs/datasets/collection/HousePricesRecords.csv\n",
    "* Dataset Cleaning Code from /jupyter_notebooks/03_Data_Cleaning.ipynb\n",
    "* Conclusions for transformations from Feature Engineering jupyter_notebooks/04_Feature_Engineering.ipynb\n",
    "\n",
    "## Outputs\n",
    "* Train Set: Features and Target\n",
    "* Test Set: Features and Target\n",
    "* Feature Engineering Pipeline\n",
    "* Modeling Pipeline\n",
    "* Features Importance Plot"
   ],
   "id": "3aaf88d26c42c1f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Change working directory\n",
    "In This section we will get location of current directory and move one step up, to parent folder, so App will be accessing project folder.\n",
    "\n",
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ],
   "id": "75a72d0651596244"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ],
   "id": "84e53adb39c40ff0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chdir() defines the new current directory"
   ],
   "id": "624018c3aea597b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"you have set a new current directory\")"
   ],
   "id": "d0307cd1e623595e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Confirm new current directory",
   "id": "b4e467105bdd1e91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ],
   "id": "45512d37254c92ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading Dataset",
   "id": "3789f66254e08f44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"outputs/datasets/collection/HousePricesRecords.csv\")\n",
    "df.head()"
   ],
   "id": "9dd310e3dcb6619f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cleaning Dataset",
   "id": "8d75e20fc7b2e13f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.loc[:, 'LotFrontage'] = df['LotFrontage'].fillna(70)\n",
    "\n",
    "# Lists of columns grouped by their fill values and type conversions\n",
    "fill_zero_and_convert = ['1stFlrSF', '2ndFlrSF', 'GarageArea', 'GarageYrBlt',\n",
    "                         'EnclosedPorch', 'MasVnrArea', 'WoodDeckSF', 'BedroomAbvGr']\n",
    "fill_none = ['BsmtExposure', 'BsmtFinType1', 'GarageFinish']\n",
    "\n",
    "# Fill missing values with zero and convert to integers for numerical columns\n",
    "df[fill_zero_and_convert] = df[fill_zero_and_convert].fillna(0).astype(int)\n",
    "\n",
    "# Fill missing values with 'None' for categorical columns\n",
    "df[fill_none] = df[fill_none].fillna('None')\n",
    "df['LotFrontage'] = df['LotFrontage'].round().astype(int)\n",
    "\n",
    "df.loc[df['2ndFlrSF'] == 0, 'BedroomAbvGr'] = df['BedroomAbvGr'].replace(0, 2)\n",
    "df.loc[df['2ndFlrSF'] > 0, 'BedroomAbvGr'] = df['BedroomAbvGr'].replace(0, 3)\n",
    "\n",
    "# Swap values where '2ndFlrSF' is greater than '1stFlrSF'\n",
    "swap_idx = df['2ndFlrSF'] > df['1stFlrSF']\n",
    "df.loc[swap_idx, ['1stFlrSF', '2ndFlrSF']] = df.loc[swap_idx, ['2ndFlrSF', '1stFlrSF']].values\n",
    "\n",
    "# Define features and their 'no presence' values\n",
    "basement_features = ['BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF']\n",
    "features_and_values = {\"BsmtExposure\": \"None\", \"BsmtFinType1\": \"None\", \"BsmtFinSF1\": 0, \"BsmtUnfSF\": 0,\n",
    "                       \"TotalBsmtSF\": 0}\n",
    "\n",
    "# Check and update inconsistencies for each feature\n",
    "for feature in basement_features:\n",
    "    primary_value = features_and_values[feature]\n",
    "    df['Consistency'] = df.apply(\n",
    "        lambda row: all(row[f] == v for f, v in features_and_values.items()) if row[feature] == primary_value else True,\n",
    "        axis=1\n",
    "    )\n",
    "    inconsistent_idx = df[~df['Consistency']].index\n",
    "    if feature in ['BsmtExposure', 'BsmtFinType1']:\n",
    "        correction = 'No' if feature == 'BsmtExposure' else 'Unf'\n",
    "        df.loc[inconsistent_idx, feature] = correction\n",
    "\n",
    "# Dropping new created column Consistency\n",
    "df = df.drop(columns=['Consistency'])\n",
    "\n",
    "# Correct zero values and adjust inconsistent records using vectorized operations\n",
    "df.loc[df['BsmtUnfSF'] == 0, 'BsmtUnfSF'] = df['TotalBsmtSF'] - df['BsmtFinSF1']\n",
    "df.loc[df['BsmtFinSF1'] == 0, 'BsmtFinSF1'] = df['TotalBsmtSF'] - df['BsmtUnfSF']\n",
    "df.loc[df['TotalBsmtSF'] == 0, 'TotalBsmtSF'] = df['BsmtUnfSF'] + df['BsmtFinSF1']\n",
    "\n",
    "# Identify and adjust records with inconsistent basement measurements using a ratio (example: 3)\n",
    "mask = df['BsmtFinSF1'] + df['BsmtUnfSF'] != df['TotalBsmtSF']\n",
    "df.loc[mask, 'BsmtUnfSF'] = (df.loc[mask, 'TotalBsmtSF'] / 3).astype(int)\n",
    "df.loc[mask, 'BsmtFinSF1'] = df.loc[mask, 'TotalBsmtSF'] - df.loc[mask, 'BsmtUnfSF']\n",
    "\n",
    "# Define a dictionary for checking consistency based on 'GarageFinish'\n",
    "features_and_values = {\"GarageArea\": 0, \"GarageFinish\": 'None', \"GarageYrBlt\": 0}\n",
    "\n",
    "\n",
    "def check_consistency(df, primary_feature):\n",
    "    primary_value = features_and_values[primary_feature]\n",
    "    return df.apply(\n",
    "        lambda row: all(row[feature] == value for feature, value in features_and_values.items())\n",
    "        if row[primary_feature] == primary_value else True, axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "# Apply consistency check and correct 'GarageFinish'\n",
    "consistency_mask = check_consistency(df, 'GarageFinish')\n",
    "df.loc[~consistency_mask, 'GarageFinish'] = 'Unf'\n",
    "\n",
    "# Correct garage years that are earlier than the house build year\n",
    "df.loc[df['GarageYrBlt'] < df['YearBuilt'], 'GarageYrBlt'] = df['YearBuilt']"
   ],
   "id": "7fd8b0417ef65504",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Exploration\n",
    "Before exploring data and doing transformations, as we decided earlier, we will select these features:"
   ],
   "id": "ce222f2402f6e5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hypothesis_1_features= [\"BsmtFinType1\", \"KitchenQual\", \"OverallQual\", \"GarageFinish\", \"BsmtExposure\", \"GrLivArea\", \"GarageArea\", \"YearBuilt\", \"1stFlrSF\", \"TotalBsmtSF\", \"SalePrice\"]\n",
    "df = df[hypothesis_1_features]\n",
    "df.head()"
   ],
   "id": "3f68f0fedc87a0d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns='SalePrice')\n",
    "y = df['SalePrice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
   ],
   "id": "f80b313366f049f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f5f5cb59c8c7e169"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Machine Learning",
   "id": "f3077ebeb6a8d911"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "### Feature Engineering\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine import transformation as vt\n",
    "\n",
    "### Feat Selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Custom Transformer for dividing 'YearBuilt' by 1e69\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class DivideByConstant(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, constant=1e69):\n",
    "        self.constant = constant\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X['YearBuilt'] = X['YearBuilt'] / self.constant\n",
    "        return X\n",
    "\n",
    "\n",
    "def model_pipeline(model):\n",
    "    pipeline_base = Pipeline([\n",
    "        # Feature Engineering\n",
    "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
    "                                                     variables=['BsmtExposure', 'BsmtFinType1', 'GarageFinish',\n",
    "                                                                'KitchenQual'])),\n",
    "        ('BoxCoxTransformer', BoxCoxTransformer(variables=['GrLivArea', 'YearBuilt'])),\n",
    "        # Divide 'YearBuilt' by 1e69\n",
    "        ('DivideByConstant', DivideByConstant(constant=1e69)),\n",
    "        ('YeoJohnsonTransformer', vt.YeoJohnsonTransformer(variables=['1stFlrSF', 'TotalBsmtSF'])),\n",
    "\n",
    "        (\"feat_selection\", SelectFromModel(model)),\n",
    "\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "\n",
    "    return pipeline_base"
   ],
   "id": "7a58bc2bddf07de0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ML Pipeline for Modeling and Hyperparameters Optimization\n",
    "\n",
    "This is custom Class Hyperparameter Optimization"
   ],
   "id": "84dc27d100d55d1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine.transformation import BoxCoxTransformer, YeoJohnsonTransformer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class grid_cv_search_hp:\n",
    "    \"\"\"\n",
    "    Class to perform hyperparameter optimization across multiple machine learning models.\n",
    "\n",
    "    Attributes:\n",
    "        models (dict): Dictionary of models to evaluate.\n",
    "        params (dict): Dictionary of hyperparameters for the models.\n",
    "        grid_searches (dict): Dictionary to store the results of GridSearchCV.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        \"\"\"\n",
    "        Initializes the HyperparameterOptimizationSearch with models and parameters.\n",
    "\n",
    "        Args:\n",
    "            models (dict): A dictionary of model names and instances.\n",
    "            params (dict): A dictionary of model names and their hyperparameters.\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring='r2', refit=False):\n",
    "        \"\"\"\n",
    "        Perform hyperparameter optimization using GridSearchCV for each model.\n",
    "\n",
    "        Args:\n",
    "            X (array-like): Training data features.\n",
    "            y (array-like): Training data target values.\n",
    "            cv (int): Number of cross-validation folds.\n",
    "            n_jobs (int): Number of jobs to run in parallel.\n",
    "            verbose (int): Controls the verbosity of the output.\n",
    "            scoring (str): Scoring metric for model evaluation.\n",
    "            refit (bool): Whether to refit the best model on the whole dataset after searching.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        for key in self.models:\n",
    "            print(f\"\\nOptimizing hyperparameters for {key}...\\n\")\n",
    "            model = model_pipeline(self.models[key])\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, verbose=verbose, scoring=scoring, refit=refit)\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        \"\"\"\n",
    "        Summarize the grid search results.\n",
    "\n",
    "        Args:\n",
    "            sort_by (str): The column to sort the results by.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: A pandas DataFrame containing the summary of grid search results.\n",
    "            dict: The grid search results.\n",
    "        \"\"\"\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = f\"split{i}_test_score\"\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append(row(k, s, p))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns += [c for c in df.columns if c not in columns]\n",
    "        return df[columns], self.grid_searches\n"
   ],
   "id": "bebb2cba05dcd497",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Grid Search CV\n",
    "\n",
    "For this time being we will use default hyperparameters, just to select best algorithms"
   ],
   "id": "f9f113541180514c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### ML algorithms \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "models_quick_search = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    'LinearRegression': {},\n",
    "    \"DecisionTreeRegressor\": {},\n",
    "    \"RandomForestRegressor\": {},\n",
    "    \"ExtraTreesRegressor\": {},\n",
    "    \"AdaBoostRegressor\": {},\n",
    "    \"GradientBoostingRegressor\": {},\n",
    "    \"XGBRegressor\": {},\n",
    "}"
   ],
   "id": "10c625d779cae244",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Running Grid Search CV",
   "id": "e61feca22f472f5a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Results Inspection",
   "id": "e3aaf906f555480d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search = grid_cv_search_hp(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5, refit=False)"
   ],
   "id": "d7f0e5efd27e38df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary()\n",
    "grid_search_summary"
   ],
   "id": "8f27c51e2b115079",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can see that GradientBoostingRegressor shows most promising results, mean = 0.796797\n",
    "Now we will add extra HyperParameters"
   ],
   "id": "951d2801cb8ac903"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "models_tuning_search = {\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "\n",
    "}\n",
    "param_grid = {\n",
    "    \"GradientBoostingRegressor\": {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__learning_rate': [0.05, 0.1],\n",
    "        'model__max_depth': [3, 5],\n",
    "        'model__min_samples_split': [2],\n",
    "        'model__min_samples_leaf': [1]\n",
    "    }\n",
    "}"
   ],
   "id": "a7dff9d6dc2a69ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search = grid_cv_search_hp(models=models_tuning_search, params=param_grid)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5, refit=True)"
   ],
   "id": "20ca6514b7633a06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary()\n",
    "grid_search_summary"
   ],
   "id": "f04e2add8d9ab224",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Yay, we managed to increase mean from 0.796797 to 0.805486. not a lot but still something.",
   "id": "d9a4d56409a183e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Selecting best model",
   "id": "363f8deb7b017bbb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_model = grid_search_summary.iloc[0]['estimator']\n",
    "best_model"
   ],
   "id": "9f486b263f820d1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Parameters for best model",
   "id": "4b46f7f9e5737b6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_parameters = grid_search_pipelines[best_model].best_params_\n",
    "best_parameters"
   ],
   "id": "55b3dc42b80b6d29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ],
   "id": "50182ad9226bf9a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Accessing Feature Importance",
   "id": "f2473c06ac24a8f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "def plot_feature_importance_absolute(selected_pipeline, feat_eng_steps):\n",
    "    try:\n",
    "        # Number of data cleaning and feature engineering steps\n",
    "        data_cleaning_feat_eng_steps = feat_eng_steps\n",
    "\n",
    "        # Extract the sub-pipeline up to the feature engineering step\n",
    "        transformer_pipeline = Pipeline(selected_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
    "\n",
    "        # Ensure the pipeline up to this point consists only of transformers\n",
    "        if not hasattr(transformer_pipeline, 'transform'):\n",
    "            raise AttributeError(\"The sub-pipeline does not support transform operation.\")\n",
    "\n",
    "        # Transform the training data\n",
    "        X_transformed = transformer_pipeline.transform(X_train)\n",
    "\n",
    "        # Get the transformed feature names\n",
    "        if hasattr(X_transformed, 'columns'):\n",
    "            transformed_feature_names = X_transformed.columns\n",
    "        else:\n",
    "            transformed_feature_names = [f'feature_{i}' for i in range(X_transformed.shape[1])]\n",
    "\n",
    "        # Get the support mask for the selected features\n",
    "        feature_support_mask = selected_pipeline.named_steps['feat_selection'].get_support()\n",
    "\n",
    "        if len(feature_support_mask) != len(transformed_feature_names):\n",
    "            raise ValueError(\"The feature support mask length does not match the number of transformed features.\")\n",
    "\n",
    "        # Select the features and their importances\n",
    "        selected_features = pd.Index(transformed_feature_names)[feature_support_mask].to_list()\n",
    "        feature_importances = selected_pipeline.named_steps['model'].feature_importances_\n",
    "\n",
    "        # DataFrame to display feature importances\n",
    "        df_feature_importances = pd.DataFrame({\n",
    "            'Feature': selected_features,\n",
    "            'Importance': feature_importances\n",
    "        }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "        # Plotting the feature importances\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x='Importance', y='Feature', data=df_feature_importances)\n",
    "        plt.xlabel('Importance')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.title('Feature Importances')\n",
    "        plt.show()\n",
    "\n",
    "    except AttributeError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"ValueError: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ],
   "id": "df62143bc114f658",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_feature_importance_absolute(best_regressor_pipeline, 3)",
   "id": "a71df1d670da7a4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluating Model on Train and Test Sets",
   "id": "212be54b4767cc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    \"\"\"\n",
    "    Evaluates the performance of a regression model on both the training and test sets.\n",
    "    \n",
    "    Args:\n",
    "        X_train (array-like): Training data features.\n",
    "        y_train (array-like): Training data target values.\n",
    "        X_test (array-like): Test data features.\n",
    "        y_test (array-like): Test data target values.\n",
    "        pipeline (Pipeline): The regression model pipeline to evaluate.\n",
    "    \"\"\"\n",
    "    r2_train, mae_train, mse_train, rmse_train, msle_train = regression_evaluation(X_train, y_train, pipeline)\n",
    "    r2_test, mae_test, mse_test, rmse_test, msle_test = regression_evaluation(X_test, y_test, pipeline)\n",
    "    return (r2_train, mae_train, mse_train, rmse_train, msle_train), (r2_test, mae_test, mse_test, rmse_test, msle_test)\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    \"\"\"\n",
    "    Evaluates a regression model on a given dataset and prints key metrics.\n",
    "    \n",
    "    Args:\n",
    "        X (array-like): Data features.\n",
    "        y (array-like): Data target values.\n",
    "        pipeline (Pipeline): The regression model pipeline to evaluate.\n",
    "    \"\"\"\n",
    "    prediction = pipeline.predict(X)\n",
    "    r2 = r2_score(y, prediction)\n",
    "    mae = mean_absolute_error(y, prediction)\n",
    "    mse = mean_squared_error(y, prediction)\n",
    "    rmse = np.sqrt(mse)\n",
    "    msle = mean_squared_log_error(y, prediction)\n",
    "\n",
    "\n",
    "    return r2, mae, mse, rmse, msle\n",
    "\n",
    "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "    \"\"\"\n",
    "    Plots actual vs predicted values for both training and test sets.\n",
    "    \n",
    "    Args:\n",
    "        X_train (array-like): Training data features.\n",
    "        y_train (array-like): Training data target values.\n",
    "        X_test (array-like): Test data features.\n",
    "        y_test (array-like): Test data target values.\n",
    "        pipeline (Pipeline): The regression model pipeline to evaluate.\n",
    "        alpha_scatter (float): Transparency of the scatter plot points.\n",
    "    \"\"\"\n",
    "    pred_train = pipeline.predict(X_train)\n",
    "    pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 12))\n",
    "\n",
    "    # Train set evaluation\n",
    "    r2_train, mae_train, mse_train, rmse_train, msle_train = regression_evaluation(X_train, y_train, pipeline)\n",
    "    # Test set evaluation\n",
    "    r2_test, mae_test, mse_test, rmse_test, msle_test = regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "    # Train plot: Actual vs Predicted\n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0, 0], color='blue')\n",
    "    axes[0, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--')\n",
    "    axes[0, 0].set_xlabel(\"Actual Values\")\n",
    "    axes[0, 0].set_ylabel(\"Predictions\")\n",
    "    axes[0, 0].set_title(\"Train Set: Actual vs Predicted\")\n",
    "    train_metrics_text = (f'R2: {round(r2_train, 3)}\\n'\n",
    "                          f'MAE: {round(mae_train, 3)}\\n'\n",
    "                          f'MSE: {round(mse_train, 3)}\\n'\n",
    "                          f'RMSE: {round(rmse_train, 3)}\\n'\n",
    "                          f'MSLE: {round(msle_train, 3)}')\n",
    "    axes[0, 0].text(0.05, 0.95, train_metrics_text, transform=axes[0, 0].transAxes, fontsize=10,\n",
    "                    verticalalignment='top', bbox=dict(boxstyle='round', alpha=0.1))\n",
    "\n",
    "    # Test plot: Actual vs Predicted\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[0, 1], color='green')\n",
    "    axes[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    axes[0, 1].set_xlabel(\"Actual Values\")\n",
    "    axes[0, 1].set_ylabel(\"Predictions\")\n",
    "    axes[0, 1].set_title(\"Test Set: Actual vs Predicted\")\n",
    "    test_metrics_text = (f'R2: {round(r2_test, 3)}\\n'\n",
    "                         f'MAE: {round(mae_test, 3)}\\n'\n",
    "                         f'MSE: {round(mse_test, 3)}\\n'\n",
    "                         f'RMSE: {round(rmse_test, 3)}\\n'\n",
    "                         f'MSLE: {round(msle_test, 3)}')\n",
    "    axes[0, 1].text(0.05, 0.95, test_metrics_text, transform=axes[0, 1].transAxes, fontsize=10,\n",
    "                    verticalalignment='top', bbox=dict(boxstyle='round', alpha=0.1))\n",
    "\n",
    "    # Residuals plot: Train\n",
    "    residuals_train = y_train - pred_train\n",
    "    sns.scatterplot(x=pred_train, y=residuals_train, alpha=alpha_scatter, ax=axes[1, 0], color='blue')\n",
    "    axes[1, 0].axhline(0, color='r', linestyle='--')\n",
    "    axes[1, 0].set_xlabel(\"Predictions\")\n",
    "    axes[1, 0].set_ylabel(\"Residuals\")\n",
    "    axes[1, 0].set_title(\"Train Set: Residuals\")\n",
    "\n",
    "    # Residuals plot: Test\n",
    "    residuals_test = y_test - pred_test\n",
    "    sns.scatterplot(x=pred_test, y=residuals_test, alpha=alpha_scatter, ax=axes[1, 1], color='green')\n",
    "    axes[1, 1].axhline(0, color='r', linestyle='--')\n",
    "    axes[1, 1].set_xlabel(\"Predictions\")\n",
    "    axes[1, 1].set_ylabel(\"Residuals\")\n",
    "    axes[1, 1].set_title(\"Test Set: Residuals\")\n",
    "\n",
    "    # Error distribution plot: Train\n",
    "    sns.histplot(residuals_train, kde=True, ax=axes[1, 2], color='blue')\n",
    "    axes[1, 2].set_xlabel(\"Residuals\")\n",
    "    axes[1, 2].set_ylabel(\"Frequency\")\n",
    "    axes[1, 2].set_title(\"Train Set: Error Distribution\")\n",
    "\n",
    "    # Error distribution plot: Test\n",
    "    sns.histplot(residuals_test, kde=True, ax=axes[0, 2], color='green')\n",
    "    axes[0, 2].set_xlabel(\"Residuals\")\n",
    "    axes[0, 2].set_ylabel(\"Frequency\")\n",
    "    axes[0, 2].set_title(\"Test Set: Error Distribution\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "a4307e48f8f882a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ],
   "id": "c8183ba9e91bdceb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## This model is not accurate enough, as mean score of test is just 0.448\n",
    "\n",
    "At this point I believe it is just pointless even to try improving model. Better save time, effort and move on."
   ],
   "id": "30f57d56866133f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hypothesis 2: we need all features to predict Sale Price",
   "id": "d8b4af3e5d2831b1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
