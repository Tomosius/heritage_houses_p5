{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Notebook 04 - Feature Engineering\n",
    "\n",
    "## Objectives\n",
    "\n",
    "Engineer Features for:\n",
    "* Classification\n",
    "* Regression\n",
    "* Clustering\n",
    "\n",
    "## Inputs\n",
    "* outputs/datasets/cleaned/test.csv\n",
    "\n",
    "## Outputs\n",
    "* Create Clean dataset:\n",
    "    * all new datasets of cleaning will be stored in inputs/datasets/cleaning\n",
    "* Split created dataset in to 3 parts:\n",
    "    * Train\n",
    "    * Validate\n",
    "    * Test\n",
    "* all new datasets (train, validate and test) will be stored in outputs/datasets/cleaned"
   ],
   "id": "a7875c24c43c0d1e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Change working directory\n",
    "In This section we will get location of current directory and move one step up, to parent folder, so App will be accessing project folder.\n",
    "\n",
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ],
   "id": "47a32a78833a8ea4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T19:45:05.801705Z",
     "start_time": "2024-05-01T19:45:05.790491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ],
   "id": "e9401ea48b42b5ff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pecukevicius/DataspellProjects/heritage_houses_p5/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chdir() defines the new current directory"
   ],
   "id": "af8ce4b5f364e90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T19:45:05.823805Z",
     "start_time": "2024-05-01T19:45:05.805106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"you have set a new current directory\")"
   ],
   "id": "374d41e491f68f3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you have set a new current directory\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Confirm new current directory",
   "id": "59f6db5b4d3b9e3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T19:45:05.850946Z",
     "start_time": "2024-05-01T19:45:05.833312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ],
   "id": "7649dd275b271b0b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pecukevicius/DataspellProjects/heritage_houses_p5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading Dataset",
   "id": "891d66d7edd5b491"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T19:45:05.892527Z",
     "start_time": "2024-05-01T19:45:05.854568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('outputs/datasets/cleaned/test.parquet.gzip')\n",
    "df.head()"
   ],
   "id": "d983f77e553443e0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Unnamed: 0  1stFlrSF  2ndFlrSF  BedroomAbvGr  BsmtExposure  BsmtFinSF1  \\\n",
       "0         662      1392         0             2             3           0   \n",
       "1        1187      1624         0             2             3        1456   \n",
       "2        1305      1652         0             2             3        1572   \n",
       "3         945      1188       561             3             3        1088   \n",
       "4         269      1113         0             3             3         751   \n",
       "\n",
       "   BsmtFinType1  BsmtUnfSF  EnclosedPorch  GarageArea  ...  LotFrontage  \\\n",
       "0             6       1392              0         576  ...          120   \n",
       "1             2        168              0         757  ...           89   \n",
       "2             2         80              0         840  ...          108   \n",
       "3             3          0            244         456  ...           98   \n",
       "4             1        392              0         504  ...           70   \n",
       "\n",
       "   MasVnrArea  OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  WoodDeckSF  \\\n",
       "0         216            0            3            6         1392           0   \n",
       "1           0          114            5            8         1624           0   \n",
       "2         300          102            5            9         1652           0   \n",
       "3           0            0            6            5         1088           0   \n",
       "4         174           30            7            6         1143           0   \n",
       "\n",
       "   YearBuilt  YearRemodAdd  SalePrice  \n",
       "0       1968          1968     110000  \n",
       "1       1994          1995     262000  \n",
       "2       2006          2007     325000  \n",
       "3       1890          1996     124900  \n",
       "4       1976          1976     148000  \n",
       "\n",
       "[5 rows x 25 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>...</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>662</td>\n",
       "      <td>1392</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1392</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1392</td>\n",
       "      <td>0</td>\n",
       "      <td>1968</td>\n",
       "      <td>1968</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1187</td>\n",
       "      <td>1624</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1456</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>757</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1624</td>\n",
       "      <td>0</td>\n",
       "      <td>1994</td>\n",
       "      <td>1995</td>\n",
       "      <td>262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1305</td>\n",
       "      <td>1652</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1572</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>840</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>300</td>\n",
       "      <td>102</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1652</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>2007</td>\n",
       "      <td>325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>945</td>\n",
       "      <td>1188</td>\n",
       "      <td>561</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1088</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>456</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1088</td>\n",
       "      <td>0</td>\n",
       "      <td>1890</td>\n",
       "      <td>1996</td>\n",
       "      <td>124900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>269</td>\n",
       "      <td>1113</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>751</td>\n",
       "      <td>1</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>504</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>174</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1143</td>\n",
       "      <td>0</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>148000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Exploration\n",
    "Before exploring data and doing transformations, as we decided earlier, we will select these features:"
   ],
   "id": "46a82af219cc1b93"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-01T19:45:05.896370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "pandas_report = ProfileReport(df, minimal=True)\n",
    "pandas_report.to_notebook_iframe()"
   ],
   "id": "87b2b88fc9c4d8d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Features Engineering",
   "id": "cb176202ca1c18bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Functions for transforming\n",
    "\n",
    "We have added extra feature - results\n",
    "It will be printed out on each analysis, also at the end of FeatureEngineeringAnalysis it will be returned to us, so we can analyze it bit easier."
   ],
   "id": "ab8c25b90e16423d"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from scipy.stats import skew, kurtosis, shapiro\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def FeatureEngineeringAnalysis(df, analysis_type=None):\n",
    "    \"\"\"\n",
    "    - used for quick feature engineering on numerical and categorical variables\n",
    "    to decide which transformation can better transform the distribution shape\n",
    "    - Once transformed, use a reporting tool, like ydata-profiling, to evaluate distributions\n",
    "    \"\"\"\n",
    "    check_missing_values(df)\n",
    "    allowed_types = ['numerical', 'ordinal_encoder', 'outlier_winsorizer']\n",
    "    check_user_entry_on_analysis_type(analysis_type, allowed_types)\n",
    "    list_column_transformers = define_list_column_transformers(analysis_type)\n",
    "\n",
    "    # Loop in each variable and engineer the data according to the analysis type\n",
    "    df_feat_eng = pd.DataFrame([])\n",
    "    for column in df.columns:\n",
    "        # create additional columns (column_method) to apply the methods\n",
    "        df_feat_eng = pd.concat([df_feat_eng, df[column]], axis=1)\n",
    "        for method in list_column_transformers:\n",
    "            df_feat_eng[f\"{column}_{method}\"] = df[column]\n",
    "\n",
    "        # Apply transformers in respective column_transformers\n",
    "        df_feat_eng, list_applied_transformers = apply_transformers(\n",
    "            analysis_type, df_feat_eng, column)\n",
    "\n",
    "        # For each variable, assess how the transformations perform\n",
    "        transformer_evaluation(\n",
    "            column, list_applied_transformers, analysis_type, df_feat_eng)\n",
    "\n",
    "    return df_feat_eng\n",
    "\n",
    "\n",
    "def check_user_entry_on_analysis_type(analysis_type, allowed_types):\n",
    "    \"\"\" Check analysis type \"\"\"\n",
    "    if analysis_type is None:\n",
    "        raise SystemExit(\n",
    "            f\"You should pass analysis_type parameter as one of the following options: {allowed_types}\")\n",
    "    if analysis_type not in allowed_types:\n",
    "        raise SystemExit(\n",
    "            f\"analysis_type argument should be one of these options: {allowed_types}\")\n",
    "\n",
    "\n",
    "def check_missing_values(df):\n",
    "    if df.isna().sum().sum() != 0:\n",
    "        raise SystemExit(\n",
    "            f\"There is a missing value in your dataset. Please handle that before getting into feature engineering.\")\n",
    "\n",
    "\n",
    "def define_list_column_transformers(analysis_type):\n",
    "    \"\"\" Set suffix columns according to analysis_type\"\"\"\n",
    "    list_column_transformers = []\n",
    "    if analysis_type == 'numerical':\n",
    "        list_column_transformers = [\n",
    "            \"log_e\", \"log_10\", \"reciprocal\", \"power\", \"box_cox\", \"yeo_johnson\"]\n",
    "\n",
    "    elif analysis_type == 'ordinal_encoder':\n",
    "        list_column_transformers = [\"ordinal_encoder\"]\n",
    "\n",
    "    elif analysis_type == 'outlier_winsorizer':\n",
    "        list_column_transformers = ['iqr']\n",
    "\n",
    "    return list_column_transformers\n",
    "\n",
    "\n",
    "def apply_transformers(analysis_type, df_feat_eng, column):\n",
    "    list_applied_transformers=[]\n",
    "    for col in df_feat_eng.select_dtypes(include='category').columns:\n",
    "        df_feat_eng[col] = df_feat_eng[col].astype('object')\n",
    "\n",
    "    if analysis_type == 'numerical':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_Numerical(\n",
    "            df_feat_eng, column)\n",
    "\n",
    "    elif analysis_type == 'outlier_winsorizer':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_OutlierWinsorizer(\n",
    "            df_feat_eng, column)\n",
    "\n",
    "    elif analysis_type == 'ordinal_encoder':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_CategoricalEncoder(\n",
    "            df_feat_eng, column)\n",
    "\n",
    "    return df_feat_eng, list_applied_transformers\n",
    "\n",
    "\n",
    "def transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng):\n",
    "    # For each variable, assess how the transformations perform\n",
    "    print(f\"* Variable Analyzed: {column}\")\n",
    "    print(f\"* Applied transformation: {list_applied_transformers} \\n\")\n",
    "\n",
    "    for col in [column] + list_applied_transformers:\n",
    "    \n",
    "        if analysis_type != 'ordinal_encoder':\n",
    "            DiagnosticPlots_Numerical(df_feat_eng, col)\n",
    "\n",
    "\n",
    "        else:\n",
    "            if col == column:\n",
    "                DiagnosticPlots_Categories(df_feat_eng, col)\n",
    "            else:\n",
    "                DiagnosticPlots_Numerical(df_feat_eng, col)\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "def DiagnosticPlots_Categories(df_feat_eng, col):\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.countplot(data=df_feat_eng, x=col, palette=[\n",
    "        '#432371'], order=df_feat_eng[col].value_counts().index)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.suptitle(f\"{col}\", fontsize=30, y=1.05)\n",
    "    plt.show()\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def DiagnosticPlots_Numerical(df, variable):\n",
    "    \"\"\"\n",
    "    Generate diagnostic plots for a numerical variable including histogram, QQ plot, and boxplot.\n",
    "    Additionally, calculate and display skewness, kurtosis, and Shapiro-Wilk test p-value.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the variable.\n",
    "        variable (str): The name of the variable to analyze.\n",
    "    \"\"\"\n",
    "    # Calculate statistics\n",
    "    skewness = skew(df[variable].dropna())  # Skewness\n",
    "    kurtosis_value = kurtosis(df[variable].dropna())  # Kurtosis\n",
    "    _, p_value = shapiro(df[variable].dropna())  # Shapiro-Wilk test\n",
    "\n",
    "    # Create plots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    sns.histplot(data=df, x=variable, kde=True, element=\"step\", ax=axes[0])\n",
    "    stats.probplot(df[variable], dist=\"norm\", plot=axes[1])\n",
    "    sns.boxplot(x=df[variable], ax=axes[2])\n",
    "\n",
    "    # Set titles including statistics\n",
    "    axes[0].set_title(f'Histogram\\nSkewness: {skewness:.3f}')\n",
    "    axes[1].set_title('QQ Plot')\n",
    "    axes[2].set_title('Boxplot')\n",
    "\n",
    "    # Display Shapiro-Wilk test result on figure\n",
    "    fig.suptitle(f\"{variable} (Skewness: {skewness:.3f}, Kurtosis: {kurtosis_value:.3f}, Shapiro-Wilk p-value: {p_value:.3g})\", fontsize=16, y=1.05)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def FeatEngineering_CategoricalEncoder(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "    try:\n",
    "        encoder = OrdinalEncoder(encoding_method='arbitrary', variables=[\n",
    "            f\"{column}_ordinal_encoder\"])\n",
    "        df_feat_eng = encoder.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_ordinal_encoder\")\n",
    "\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_ordinal_encoder\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked\n",
    "\n",
    "\n",
    "def FeatEngineering_OutlierWinsorizer(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "\n",
    "    # Winsorizer iqr\n",
    "    try:\n",
    "        disc = Winsorizer(\n",
    "            capping_method='iqr', tail='both', fold=1.5, variables=[f\"{column}_iqr\"])\n",
    "        df_feat_eng = disc.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_iqr\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_iqr\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, RobustScaler, QuantileTransformer, FunctionTransformer\n",
    "from feature_engine.transformation import LogTransformer, ReciprocalTransformer, BoxCoxTransformer, \\\n",
    "    YeoJohnsonTransformer\n",
    "\n",
    "\n",
    "def FeatEngineering_Numerical(df_feat_eng, column):\n",
    "    \"\"\"\n",
    "    Applies various feature engineering transformations to a specified column in the dataframe.\n",
    "\n",
    "    Parameters:\n",
    "        df_feat_eng (DataFrame): The dataframe containing the features for transformation.\n",
    "        column (str): The specific column on which to apply the transformations.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The transformed dataframe and a list of successfully applied transformation methods.\n",
    "    \"\"\"\n",
    "    list_methods_worked = []\n",
    "\n",
    "    # LogTransformer base e\n",
    "    try:\n",
    "        lt = LogTransformer(variables=[column])\n",
    "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_log_e\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_log_e\"], axis=1, inplace=True)\n",
    "\n",
    "    # LogTransformer base 10\n",
    "    try:\n",
    "        lt = LogTransformer(variables=[column], base=10)\n",
    "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_log_10\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_log_10\"], axis=1, inplace=True)\n",
    "\n",
    "    # ReciprocalTransformer\n",
    "    try:\n",
    "        rt = ReciprocalTransformer(variables=[column])\n",
    "        df_feat_eng = rt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_reciprocal\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_reciprocal\"], axis=1, inplace=True)\n",
    "\n",
    "    # PowerTransformer (Yeo-Johnson)\n",
    "    try:\n",
    "        pt = PowerTransformer(method='yeo-johnson')\n",
    "        df_feat_eng[f\"{column}_power\"] = pt.fit_transform(df_feat_eng[[column]])\n",
    "        list_methods_worked.append(f\"{column}_power\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_power\"], axis=1, inplace=True)\n",
    "\n",
    "    # BoxCoxTransformer\n",
    "    try:\n",
    "        bct = BoxCoxTransformer(variables=[column])\n",
    "        df_feat_eng = bct.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_box_cox\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_box_cox\"], axis=1, inplace=True)\n",
    "\n",
    "    # YeoJohnsonTransformer\n",
    "    try:\n",
    "        yjt = YeoJohnsonTransformer(variables=[column])\n",
    "        df_feat_eng = yjt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_yeo_johnson\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_yeo_johnson\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked\n",
    "\n"
   ],
   "id": "1a86dcc49cbd4db0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inspecting dataframe for columns that might not need to be transformed\n",
   "id": "43bd957b0e3c25cf"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "df_transformed = FeatureEngineeringAnalysis(df=df, analysis_type='numerical')",
   "id": "5f38744012df06c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Based on plots above we can select best transformations for each feature:\n",
    "1. TotalBsmtSF:\n",
    "* Quantile Uniform\n",
    "* Sine\n",
    "* Cosine\n",
    "2. 1stFlrSF:\n",
    "* Original Values\n",
    "* Log-e\n",
    "* Box_Cox\n",
    "* Min_Max\n",
    "* Quantile Normal\n",
    "3. YearBuilt:\n",
    "* Quantile Uniform\n",
    "* Yeo Johnson\n",
    "* Power\n",
    "* Min_Max \n",
    "4. GarageArea:\n",
    "* Quantile Uniform\n",
    "* Sine\n",
    "* Cosine\n",
    "* Yeo Johnson\n",
    "5. GarageYrBlt:\n",
    "* Quantile Uniform\n",
    "* Quantile Normal\n",
    "* Cosine\n",
    "6. OverallQual:\n",
    "* Power\n",
    "* Original Values\n",
    "* Min_Max\n",
    "* Max_Abs\n",
    "7. GrLivArea:\n",
    "* Quantile Normal\n",
    "* Original Values\n",
    "* Max_Abs\n",
    "8. SalePrice:\n",
    "* Original Values\n",
    "* Power\n",
    "* Min Max\n",
    "* Quantile Normal"
   ],
   "id": "5f34d232d4bfa29e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Printing Transformation results\n",
    "\n",
    "We will print results as dataframe, so it will be short summary of all applied transformations, then we can analyze it"
   ],
   "id": "7e50b0eb107b6455"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e23f0bc43aa1cd17"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "def calculate_statistics(df):\n",
    "    \"\"\"\n",
    "    Calculate skewness, kurtosis, and the p-value of the Shapiro-Wilk test for each numeric feature.\n",
    "    Also, calculate mean, median, standard deviation, minimum, and maximum.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame with numeric features.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A new DataFrame with each row representing a feature and its statistics.\n",
    "    \"\"\"\n",
    "    stats_list = []  # Use a list to collect all row data\n",
    "\n",
    "    for column in df.select_dtypes(include=[np.number]).columns:\n",
    "        mean_val = df[column].mean()\n",
    "        median_val = df[column].median()\n",
    "        std_dev = df[column].std()\n",
    "        min_val = df[column].min()\n",
    "        max_val = df[column].max()\n",
    "        skewness = stats.skew(df[column], nan_policy='omit')\n",
    "        kurtosis_val = stats.kurtosis(df[column], nan_policy='omit')\n",
    "\n",
    "        # Append row to list\n",
    "        stats_list.append({\n",
    "            'Feature': column,\n",
    "            'Mean': mean_val,\n",
    "            'Median': median_val,\n",
    "            'Std Dev': std_dev,\n",
    "            'Min': min_val,\n",
    "            'Max': max_val,\n",
    "            'Skewness': skewness,\n",
    "            'Kurtosis': kurtosis_val,\n",
    "        })\n",
    "\n",
    "    # Convert list of dictionaries to DataFrame\n",
    "    stats_df = pd.DataFrame(stats_list)\n",
    "    return stats_df\n",
    "\n",
    "statistics_df = calculate_statistics(df_transformed)"
   ],
   "id": "83bdf3773d1a995c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "statistics_df.head()",
   "id": "91fd81c3e3aa12e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Now we will make code to give us at least 3 best transformation for each feature",
   "id": "da9e4aa11dc306a3"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def select_best_transformations(df, n_transformations=3):\n",
    "    \"\"\"\n",
    "    Select the best transformations for each feature based on the lowest absolute skewness and \n",
    "    the highest Shapiro-Wilk p-value.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): A DataFrame with columns 'Feature', 'Skewness', 'Kurtosis', \n",
    "                        'Shapiro-Wilk p-value', and possibly others.\n",
    "        n_transformations (int): The number of top transformations to select for each feature.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with the top transformations for each feature.\n",
    "    \"\"\"\n",
    "    # Split 'Feature' into 'Base Feature' and 'Transformation Method'\n",
    "    df[['Base Feature', 'Transformation Method']] = df['Feature'].str.split('_', n=1, expand=True)\n",
    "    df['Transformation Method'].fillna('Original', inplace=True)  # Handle cases with no underscore\n",
    "\n",
    "    # Create a new column for absolute skewness to sort by it\n",
    "    df['Abs Skewness'] = df['Skewness'].abs()\n",
    "\n",
    "    # Sort the DataFrame by absolute skewness\n",
    "    sorted_df = df.sort_values(by=['Abs Skewness'], ascending=[True])\n",
    "\n",
    "    # Group by the base feature and select the top transformations\n",
    "    top_transformations = sorted_df.groupby('Base Feature').head(n_transformations).reset_index(drop=True)\n",
    "\n",
    "    # Return the DataFrame sorted by 'Base Feature'\n",
    "    return top_transformations.sort_values(by='Base Feature')[['Base Feature', 'Skewness', 'Kurtosis', 'Transformation Method']]\n",
    "\n",
    "best_transforms = select_best_transformations(statistics_df)\n"
   ],
   "id": "d3c3db26ed519bdd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "best_transforms",
   "id": "c13b89d071848039",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Based on Selection above, if they do not exsis in previous list, we will add them:\n",
    "1. TotalBsmtSF:\n",
    "* Quantile Uniform\n",
    "* Sine\n",
    "* Cosine\n",
    "2. 1stFlrSF:\n",
    "* Original Values\n",
    "* Log-e\n",
    "* Box Cox\n",
    "* Min Max\n",
    "* Quantile Normal\n",
    "* Quantile Uniform\n",
    "* Max Abs\n",
    "3. YearBuilt:\n",
    "* Quantile Uniform\n",
    "* Yeo Johnson\n",
    "* Power\n",
    "* Min Max\n",
    "* Reciprocal \n",
    "4. GarageArea:\n",
    "* Quantile Uniform\n",
    "* Sine\n",
    "* Cosine\n",
    "* Yeo Johnson\n",
    "* Original Values\n",
    "5. GarageYrBlt:\n",
    "* Quantile Uniform\n",
    "* Quantile Normal\n",
    "* Cosine\n",
    "6. OverallQual:\n",
    "* Power\n",
    "* Original Values\n",
    "* Min Max\n",
    "* Max Abs\n",
    "* Robust\n",
    "7. GrLivArea:\n",
    "* Quantile Normal\n",
    "* Original Values\n",
    "* Max Abs\n",
    "* Quantile Uniform\n",
    "8. SalePrice:\n",
    "* Original Values\n",
    "* Power\n",
    "* Min Max\n",
    "* Quantile Normal\n",
    "* Quantile Uniform"
   ],
   "id": "dd79a74db9e9d9a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "96c0c52beabcaa32"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusions:\n",
    "\n",
    "We will add these transformations to ML Pipeline:\n",
    "\n",
    "- **Original Values** : [`1stFlrSF`, `GarageArea`, `OverallQual`, `GrLivArea`, `SalePrice`]\n",
    "- **Quantile Uniform** : [`TotalBsmtSF`, `1stFlrSF`, `YearBuilt`, `GarageArea`, `GarageYrBlt`, `GrLivArea`, `SalePrice`]\n",
    "- **Sine** : [`TotalBsmtSF`, `GarageArea`]\n",
    "- **Cosine** : [`TotalBsmtSF`, `GarageArea`, `GarageYrBlt`]\n",
    "- **Log-e** : [`1stFlrSF`]\n",
    "- **Box Cox** : [`1stFlrSF`]\n",
    "- **Min Max** : [`1stFlrSF`, `YearBuilt`, `OverallQual`, `SalePrice`]\n",
    "- **Quantile Normal** : [`1stFlrSF`, `GarageYrBlt`, `GrLivArea`, `SalePrice`]\n",
    "- **Max Abs** : [`1stFlrSF`, `OverallQual`, `GrLivArea`]\n",
    "- **Power** : [`YearBuilt`, `OverallQual`, `SalePrice`]\n",
    "- **Yeo Johnson** : [`YearBuilt`, `GarageArea`]\n",
    "- **Reciprocal** : [`YearBuilt`]\n",
    "- **Robust** : [`OverallQual`]"
   ],
   "id": "e01b035cdb49edac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Next step is ML model creation and it's evaluation",
   "id": "cc9d69b1f74340f2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
