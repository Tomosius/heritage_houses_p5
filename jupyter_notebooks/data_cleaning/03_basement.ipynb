{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Notebook 03 - Basement all features data cleaning and fixing\n",
    "\n",
    "## Objectives\n",
    "* Clean data\n",
    "* Evaluate and process missing data\n",
    "* Fix potential issues with data in given features:\n",
    "    * BsmtExposure - Refers to walkouts or garden level walls\n",
    "    * BsmtFinType1 - Rating of basement finished area\n",
    "    * BsmtFinSF1 - Type 1 finished square feet (we believe it is finished basement area)\n",
    "    * BsmtUnfSF - Unfinished square feet of basement area\n",
    "    * TotalBsmtSF - Total square feet of basement area\n",
    "\n",
    "## Inputs\n",
    "* inputs/datasets/cleaning/bedrooms.csv\n",
    "\n",
    "## Outputs\n",
    "* Clean and fix (missing and potentially wrong) data in given features\n",
    "* After cleaning is completed, we will save current dataset in inputs/datasets/cleaning/basement.csv"
   ],
   "id": "a7875c24c43c0d1e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Change working directory\n",
    "In This section we will get location of current directory and move one step up, to parent folder, so App will be accessing project folder.\n",
    "\n",
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ],
   "id": "cb656678d593177e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:38.424994Z",
     "start_time": "2024-04-29T22:12:38.402616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ],
   "id": "aebc2a0372b47511",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chdir() defines the new current directory"
   ],
   "id": "61376d0e5ecf487c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:38.442487Z",
     "start_time": "2024-04-29T22:12:38.431620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"you have set a new current directory\")"
   ],
   "id": "ad55fa3d2f5db8d0",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Confirm new current directory",
   "id": "2ef02ca3ee0c6a3c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:38.466618Z",
     "start_time": "2024-04-29T22:12:38.456896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ],
   "id": "a4c9d92dbb8cc3a9",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We need to check current working directory",
   "id": "22e5c3d0ef0ef283"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:38.677104Z",
     "start_time": "2024-04-29T22:12:38.666684Z"
    }
   },
   "cell_type": "code",
   "source": "current_dir",
   "id": "ba1df529a54df2f3",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can see that current is **jupyter_notebooks**, as current notebook is in subfolder. We will go one step up to parent directory, what will be our project main directory.\n",
    "Print out to confirm working directory"
   ],
   "id": "36cb42d41d3602a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:39.087472Z",
     "start_time": "2024-04-29T22:12:39.074874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ],
   "id": "14a35895387aca00",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9c67382aa77af8a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading Dataset",
   "id": "891d66d7edd5b491"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:40.558740Z",
     "start_time": "2024-04-29T22:12:39.195511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"inputs/datasets/cleaning/bedrooms.csv\")\n",
    "df.head()"
   ],
   "id": "d983f77e553443e0",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exploring Data\n",
    "\n",
    "We will get all features that are missing data as a list, first we get given features datatypes"
   ],
   "id": "273e298ac770d848"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:40.578283Z",
     "start_time": "2024-04-29T22:12:40.565554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns_of_interest = ['BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF']\n",
    "column_types = df[columns_of_interest].dtypes\n",
    "\n",
    "# Display the data types of these columns\n",
    "print(\"Data types of the specified columns:\")\n",
    "print(column_types)"
   ],
   "id": "f9896b00178d5c21",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Checking if there is any missing values in given column",
   "id": "8b8593878246a3ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:40.614426Z",
     "start_time": "2024-04-29T22:12:40.593839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if there are any  missing values in these columns\n",
    "missing_features = df[['BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF']].isnull().sum()\n",
    "\n",
    "# Display the number of missing values per column after filling\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_features)"
   ],
   "id": "23365b9ed400d04c",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can see that 2 features has missing values - BsmtExposure and BsmtType1\n",
    "\n",
    "We will fill all missing values with None, as it is object type (None in our dataset refers to No Basement). We will inspect later if all values are correct"
   ],
   "id": "b7ad03dd6d8882ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4b0555aa1a0458b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:40.638465Z",
     "start_time": "2024-04-29T22:12:40.625392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['BsmtExposure'] = df['BsmtExposure'].fillna('None')\n",
    "df['BsmtFinType1'] = df['BsmtFinType1'].fillna('None')"
   ],
   "id": "14bc76a63e4737a0",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Adding code to cleaning pipe:\n",
    "```python\n",
    "df['BsmtExposure'] = df['BsmtExposure'].fillna('None')\n",
    "df['BsmtFinType1'] = df['BsmtFinType1'].fillna('None')\n",
    "```"
   ],
   "id": "e3ae5e46d8c9c0a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For easy of code use wi will define current features as a list",
   "id": "ce4bf46530f8ada3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:40.651616Z",
     "start_time": "2024-04-29T22:12:40.642323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a list of basement-related features\n",
    "basement_features = ['BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF']"
   ],
   "id": "c3e76577b5d9b692",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Basement Consistency checking\n",
    "\n",
    "As we have filled with None missing values of BsmtFinType1, we need to explore how consistent data is between all basement features.\n",
    "\n",
    "We will create function, which one will compare given feature to remaining ones, if data is consistent:"
   ],
   "id": "3f2406e7f4b98d72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:40.674267Z",
     "start_time": "2024-04-29T22:12:40.658726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_consistency(df, primary_feature):\n",
    "    \"\"\"\n",
    "    Checks consistency of a primary feature against a set of expected values for related features.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        primary_feature (str): The primary feature to be checked.\n",
    "    \n",
    "    Returns:\n",
    "        None: Outputs inconsistency results directly.\n",
    "    \"\"\"\n",
    "    # Directly define features and their values indicating 'no presence' in a dictionary\n",
    "    features_and_values = {\n",
    "        \"BsmtExposure\": \"None\",\n",
    "        \"BsmtFinType1\": \"None\",\n",
    "        \"BsmtFinSF1\": 0,\n",
    "        \"BsmtUnfSF\": 0,\n",
    "        \"TotalBsmtSF\": 0\n",
    "    }\n",
    "\n",
    "    # Ensure primary feature is valid\n",
    "    if primary_feature not in features_and_values:\n",
    "        print(f\"Feature {primary_feature} not defined in feature settings.\")\n",
    "        return\n",
    "\n",
    "    # Determine the primary value to check against\n",
    "    primary_value = features_and_values[primary_feature]\n",
    "\n",
    "    # Check each feature against the primary feature's condition\n",
    "    df['Consistency'] = df.apply(\n",
    "        lambda row: True if row[primary_feature] != primary_value else all(\n",
    "            row[feature] == value for feature, value in features_and_values.items() if feature != primary_feature\n",
    "        ), axis=1\n",
    "    )\n",
    "\n",
    "    # Filter and display inconsistent records\n",
    "    inconsistent_records = df[df['Consistency'] == False]\n",
    "    return inconsistent_records"
   ],
   "id": "471d47a3f7faa11b",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We loop through each feature and print the results",
   "id": "89eeb1d8fbae6a46"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:40.842041Z",
     "start_time": "2024-04-29T22:12:40.681925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loop_check_consistency(df, basement_features):\n",
    "    for feature in basement_features:\n",
    "        errors = check_consistency(df, feature)\n",
    "        error_count = errors.shape[0]  # Get the number of rows in the errors DataFrame\n",
    "        print(f\"Feature {feature} has {error_count} inconsistent rows.\")\n",
    "\n",
    "# Run the loop check consistency function\n",
    "loop_check_consistency(df, basement_features)"
   ],
   "id": "b5395fdbf452c4a5",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Consistency inspection and fixing\n",
    "\n",
    "Given dataset gives a lot of inconsistency, so we will have to address each feature separately"
   ],
   "id": "c8816f548dce5085"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:40.895597Z",
     "start_time": "2024-04-29T22:12:40.845878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BsmtExposure = check_consistency(df, 'BsmtExposure')\n",
    "BsmtExposure[basement_features]"
   ],
   "id": "cbf8abccd5fe7eea",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If there is any basement in other columns, it means there is basement, and there was a mistake on data entering.\n",
    "\n",
    "We will check replace all wrong data (None) to most frequent value of given feature in whole set"
   ],
   "id": "d85588c5711d5d1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:40.910651Z",
     "start_time": "2024-04-29T22:12:40.899893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mode_value = df['BsmtExposure'].mode()[0]  # mode() returns a Series; [0] accesses the first mode\n",
    "df.loc[BsmtExposure.index, 'BsmtExposure'] = mode_value"
   ],
   "id": "cec29ea87bb58bed",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we will check BsmtExposure again for any inconsistencies",
   "id": "75a2b13c2c5f4210"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:40.971528Z",
     "start_time": "2024-04-29T22:12:40.925371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BsmtExposure = check_consistency(df, 'BsmtExposure')\n",
    "BsmtExposure[basement_features]"
   ],
   "id": "182f6908df5cb781",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We have no mistakes in Basement Exposure",
   "id": "98b231f4fe872dbb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### BsmtFinType1 Inconsistency",
   "id": "39756652c3b57d50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:41.026082Z",
     "start_time": "2024-04-29T22:12:40.976495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BsmtFinType1 = check_consistency(df, 'BsmtFinType1')\n",
    "BsmtFinType1[basement_features]"
   ],
   "id": "6e7c2f0dfb92d29a",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We have 108 invalid records, also there is a chance, there is same mistake as with exposure.\n",
    "Will apply same mistakes fixing style"
   ],
   "id": "810cf5089cadfea6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:41.050097Z",
     "start_time": "2024-04-29T22:12:41.032700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mode_value = df['BsmtFinType1'].mode()[0]  # mode() returns a Series; [0] accesses the first mode\n",
    "df.loc[BsmtFinType1.index, 'BsmtFinType1'] = mode_value"
   ],
   "id": "3d057c3e4845cecf",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d515896e0ced6eb3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Checking again for any mistakes in BsmtFinType1",
   "id": "55880a14e1de6734"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8870d1032cf74b57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:41.101346Z",
     "start_time": "2024-04-29T22:12:41.053908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BsmtFinType1 = check_consistency(df, 'BsmtFinType1')\n",
    "BsmtFinType1[basement_features]"
   ],
   "id": "6f59b096b78f5bde",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see there is no mistakes at the moment",
   "id": "998f0e45854d8b92"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### BsmtFinSF1, BsmtUnfSF, TotalBsmtSF Inconsistency\n",
    "\n",
    "This feature represents Unfinished area of basement. \n",
    "\n",
    "Previous Cells have showed, that if there is basement, they are displayed on BsmtExposure and BsmtFinType1, where they can not be None\n",
    "\n",
    "In current cell we can have 0, as it might be correct value, as all basement is finished and are equals to 0\n",
    "But before we proceed further, we need to check, is it a correct value:\n",
    "BsmtFinSF1 + BsmtUnfSF = TotalBsmtSF"
   ],
   "id": "789e8d98d85025d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:41.131795Z",
     "start_time": "2024-04-29T22:12:41.113428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['BsmtAreaCheck'] = (df['BsmtFinSF1'] + df['BsmtUnfSF'] == df['TotalBsmtSF'])\n",
    "inconsistencies = df['BsmtAreaCheck'].value_counts()[False] if False in df['BsmtAreaCheck'].value_counts() else 0\n",
    "inconsistencies"
   ],
   "id": "723a53be98781f46",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can see that there are 167 incorrect values, This is why we will perform:\n",
    "* if BsmtUnfSF == 0, we will replace it with TotalBsmtSF - BsmtFinSF1\n",
    "* if BsmtFinSF1 == 0, we will replace it with TotalBsmtSF - BsmtUnfSF\n",
    "* if totalBsmtSF == 0, we will replace it with BsmtFinSF1 + BsmtUnfSF\n",
    "\n",
    "After that we will check for inconsistencies again\n",
    "\n",
    "also we will add part of this code to cleaning pipeline"
   ],
   "id": "c69b344c90a86948"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:41.552969Z",
     "start_time": "2024-04-29T22:12:41.510311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correcting BsmtUnfSF when it is erroneously zero\n",
    "df.loc[(df['BsmtUnfSF'] == 0), 'BsmtUnfSF'] = df['TotalBsmtSF'] - df['BsmtFinSF1']\n",
    "\n",
    "# Correcting BsmtFinSF1 when it is erroneously zero\n",
    "df.loc[(df['BsmtFinSF1'] == 0), 'BsmtFinSF1'] = df['TotalBsmtSF'] - df['BsmtUnfSF']\n",
    "\n",
    "# Correcting TotalBsmtSF when it is erroneously zero\n",
    "df.loc[(df['TotalBsmtSF'] == 0), 'TotalBsmtSF'] = df['BsmtUnfSF'] + df['BsmtFinSF1']\n",
    "\n",
    "# Adding a consistency check to verify corrections\n",
    "df['BsmtAreaCheck'] = (df['BsmtFinSF1'] + df['BsmtUnfSF'] == df['TotalBsmtSF'])\n",
    "\n",
    "# Counting and displaying inconsistencies\n",
    "inconsistencies = df['BsmtAreaCheck'].value_counts().get(False, 0)\n",
    "print(f\"Number of inconsistencies after corrections: {inconsistencies}\")\n",
    "\n",
    "df[df['BsmtAreaCheck'] == False][['BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtAreaCheck']]\n",
    "\n"
   ],
   "id": "b7fe7fcbd68a1a1f",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now we have discrepancies in basement areas between Finished and unfinished, where areas do not add up to total area.\n",
    "\n",
    "To Go further, we will get overall ratio of all dataset between finished and unfinished basements, but only for records where sum of areas matches total"
   ],
   "id": "f2e2d7acac57a231"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:42.533029Z",
     "start_time": "2024-04-29T22:12:42.512997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Filter for consistent records\n",
    "consistent_records = df[df['BsmtFinSF1'] + df['BsmtUnfSF'] == df['TotalBsmtSF']]\n",
    "\n",
    "# Step 2: Calculate the ratio of finished to unfinished areas\n",
    "# Avoid division by zero by ensuring 'BsmtUnfSF' is not zero\n",
    "consistent_records = consistent_records[consistent_records['BsmtUnfSF'] != 0]\n",
    "consistent_records['Fin_Unf_Ratio'] = consistent_records['BsmtFinSF1'] / consistent_records['BsmtUnfSF']\n",
    "\n",
    "# Step 3: Compute the overall average ratio\n",
    "# This will give us the mean ratio of finished to unfinished basement areas\n",
    "overall_ratio = consistent_records['Fin_Unf_Ratio'].mean()\n",
    "overall_ratio"
   ],
   "id": "b6133e763e6a16f3",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can now adjust Finished and Unfinished areas with given ratio, so sum of areas ads up",
   "id": "28fbbc69d18ba056"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:43.008085Z",
     "start_time": "2024-04-29T22:12:42.954992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Filter for inconsistent records\n",
    "inconsistent_records = df[df['BsmtFinSF1'] + df['BsmtUnfSF'] != df['TotalBsmtSF']]\n",
    "\n",
    "# Step 2: Adjust using the overall ratio\n",
    "for index, row in inconsistent_records.iterrows():\n",
    "    total_bsmt_sf = row['TotalBsmtSF']\n",
    "    # Calculate new values based on the overall ratio\n",
    "    new_unf_sf = int(total_bsmt_sf / (overall_ratio + 1))\n",
    "    new_fin_sf = total_bsmt_sf - new_unf_sf               \n",
    "\n",
    "    # Assign the new values back to the DataFrame\n",
    "    df.at[index, 'BsmtUnfSF'] = new_unf_sf\n",
    "    df.at[index, 'BsmtFinSF1'] = new_fin_sf\n",
    "\n",
    "# Step 3: Re-check consistency\n",
    "df['ConsistencyCheck'] = (df['BsmtFinSF1'] + df['BsmtUnfSF'] == df['TotalBsmtSF'])\n",
    "inconsistencies_after_adjustment = df['ConsistencyCheck'].value_counts().get(False, 0)\n",
    "print(f\"Number of inconsistencies after adjustments: {inconsistencies_after_adjustment}\")\n"
   ],
   "id": "604391f6d7ec36fa",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We have completed Basement data Fixing, all we need is now to check all values are correct, adds up and are consistent",
   "id": "9073128faedc9fe2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:43.671480Z",
     "start_time": "2024-04-29T22:12:43.491889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loop_check_consistency(df, basement_features)\n",
    "df['BsmtAreaCheck'] = (df['BsmtFinSF1'] + df['BsmtUnfSF'] == df['TotalBsmtSF'])\n",
    "\n",
    "inconsistencies = df['BsmtAreaCheck'].value_counts()[False] if False in df['BsmtAreaCheck'].value_counts() else 0\n",
    "print()\n",
    "print(\"Total number where areas of basement do not add up: \", inconsistencies)"
   ],
   "id": "7b84d6130dfd0054",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can ignore following rows:\n",
    "Feature BsmtFinSF1 has 430 inconsistent rows.\n",
    "Feature BsmtUnfSF has 43 inconsistent rows.\n",
    "Feature TotalBsmtSF has 0 inconsistent rows.\n",
    "\n",
    "They were used just for checking BsmtExposure and BsmtFinType1, as they can be zero, based on how much basement is finished or not"
   ],
   "id": "181e9bb26f626b5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## We have found no issues with given features\n",
    "\n",
    "We will save given dataset as outputs/data_cleaning/04_basement.csv\n",
    "Before saving, we will:\n",
    "1. Remove Columns that do not belong to given dataset\n",
    "2. Encode columns BsmtExposure and BsmtFinType1 as numbers:\n",
    "* Create file for managing all encodings encoders.py\n",
    "* create file all_encodings.json\n",
    "* encode given features\n",
    "* save encoding dictionaries in file all_encodings.json\n",
    " \n",
    "Export dataset as inputs/datasets/cleaning/basement.csv"
   ],
   "id": "79595ebee8961283"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:43.917031Z",
     "start_time": "2024-04-29T22:12:43.856402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Removing Extra columns that originally do not belong to dataset, as we have created them\n",
    "\n",
    "df_original_features = pd.read_csv(\"outputs/datasets/collection/HousePricesRecords.csv\")\n",
    "import pandas as pd\n",
    "\n",
    "# Identify columns in df that are also in df_original\n",
    "common_columns = df.columns.intersection(df_original_features.columns)\n",
    "\n",
    "# Filter df to only include those common columns\n",
    "df = df[common_columns]\n",
    "\n",
    "df.head()\n"
   ],
   "id": "e6f16e4d55d91bfe",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Encoding BsmtExposure as numbers",
   "id": "a3db3e7a54190191"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:45.631290Z",
     "start_time": "2024-04-29T22:12:44.071703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encoding given features as numbers, will reduce dataset size, what would potentially increase future calculations with dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Creating an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fitting and transforming the column to encode\n",
    "df['BsmtExposure'] = label_encoder.fit_transform(df['BsmtExposure'])\n",
    "\n",
    "# Showing the mapping\n",
    "mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Current encoding: \", mapping)\n",
    "\n",
    "# saving encoder settings\n",
    "joblib.dump(label_encoder, 'models/joblib/bsmt_exposure_encoder.joblib')\n"
   ],
   "id": "20a6ace43c3f0377",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Encoding BsmtFinType1 as numbers",
   "id": "44b0641278a544b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:45.671017Z",
     "start_time": "2024-04-29T22:12:45.643147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encoding given features as numbers, will reduce dataset size, what would potentially increase future calculations with dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Creating an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fitting and transforming the column to encode\n",
    "df['BsmtFinType1'] = label_encoder.fit_transform(df['BsmtFinType1'])\n",
    "\n",
    "# Showing the mapping\n",
    "mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Current encoding: \", mapping)\n",
    "\n",
    "joblib.dump(label_encoder, 'models/joblib/bsm_fin_type_1_encoder.joblib')"
   ],
   "id": "8c4317e0938ca493",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Saving current dataset\n",
    "\n",
    "We will save current dataset as inputs/datasets/cleaning/04_basement.csv"
   ],
   "id": "13078753fd3e7fe5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T22:12:45.721652Z",
     "start_time": "2024-04-29T22:12:45.677891Z"
    }
   },
   "cell_type": "code",
   "source": "df.to_csv('inputs/datasets/cleaning/basement.csv', index=False)",
   "id": "b4402d0f6b15e98d",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Next step is cleaning Garages - cleaning and fixing data in garages",
   "id": "ad050493d009d619"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
